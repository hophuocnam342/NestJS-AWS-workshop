[
{
	"uri": "//localhost:1313/",
	"title": "Deploy Nestjs website to AWS",
	"tags": [],
	"description": "",
	"content": "Deploy Nestjs website to AWS Overview In this lab, you will be guided on how to deploy a website running the Nestjs API backend to AWS platform. With optimal support services such as EC2, VPC, S3, Cloudfront,\u0026hellip;, your website will operate quickly, meeting the strict requirements of users. Introducing Amazon Elastic Compute Cloud (EC2) Amazon EC2 is a service that provides scalable cloud computing capabilities on AWS. Some key features:\nAmazon EC2 operates similarly to traditional virtual or physical servers, but with the ability to quickly initialize, flexibly scale resources and simple management.\nVirtual Server divides a physical server into multiple virtual servers, optimizing the use of hardware resources.\nAmazon EC2 supports a variety of workloads such as: web hosting, applications, databases, authentication services, and any task that a regular server can perform.\nIntroducing Amazon Virtual Private Cloud (Amazon VPC) Amazon VPC is a custom virtual network service within AWS Cloud, allowing you to create a separate and completely isolated network environment from the outside world. This concept is similar to designing and deploying a standalone network in a traditional on-premises data center. Key Features:\nFull control over your virtual network environment Instantiate and manage AWS resources Customize IP address ranges and network segments Flexible routing and networking configuration Full IPv4 and IPv6 support Introducing Amazon Simple Storage Service (Amazon S3) Amazon Simple Storage Service (Amazon S3) is an object storage service that provides on-demand scalability, ensuring the highest levels of data availability, security, and performance.\nS3 is built to meet the needs of customers of all sizes and industries, who can use it to store and protect any amount of data.\nS3 can be used for a variety of use cases such as data warehouses, websites, mobile applications, backup and restore, archiving, enterprise applications, IoT devices, and big data analytics. Additionally, Amazon S3 provides easy-to-use management features that help you organize your data and configure access controls to meet your specific business, organizational, and compliance requirements.\nAmazon S3 is designed to provide 99.999999999% (11 9’s) durability and stores data for millions of applications for companies worldwide.\nIntroducing Amazon Cloudfront Amazon CloudFront is a content delivery network (CDN) service from Amazon Web Services (AWS). It accelerates the delivery of web, video, application, and API content to users globally by serving content from edge locations closest to users, reducing latency and improving performance.\nKey Features:\nGlobal CDN: CloudFront has a network of edge locations around the world, enabling content delivery closer to users, reducing page load times and improving user experience.\nStatic and dynamic content delivery: CloudFront supports both static content (e.g. images, CSS, JavaScript) and dynamic content (e.g. dynamically generated web pages).\nIntegration with AWS: CloudFront integrates well with other AWS services such as Amazon S3, Amazon EC2, making it easy for companies already using AWS to deploy and manage a CDN.\nSecurity: CloudFront provides security features such as SSL/TLS encryption, access control, and integration with AWS Shield to protect against DDoS attacks.\nCost Optimization: CloudFront helps optimize costs by offloading origin servers, reducing bandwidth, and providing flexible pricing options.\nOther Features: CloudFront also supports features such as video delivery, cache management, and geographic access restrictions.\nIntroducing AWS Cognito AWS Cognito allows us to easily build login, registration, email verification, password change, password reset, etc. flows, instead of having to build DBs for users and perform many operations such as JWT, password hashing, sending verification emails, etc. This helps you focus on developing other features of the application. Users can log in directly with username and password or through third parties such as Facebook, Amazon, Google, or Apple. The two main components of Amazon Cognito are user groups and identity groups:\nUser groups: a user directory that provides sign-up and sign-in options for your web and mobile app users. Once signed in with a user group, app users can access the resources the app allows.\nIdentity groups: give your users access to other AWS services.\nIntroducing Amazon EC2 Auto Scaling Group 1. Why use Auto scaling group?\nWhen our application is put into operation, the number of visitors will change over time, so we need to regularly change (scaling) the number of instances to improve availability and save costs. To automate and be flexible in scaling work, we will have the solution of Auto Scaling Group.\n2. Overview of Auto Scaling Group\nAmazon EC2 Auto Scaling Group (ASG) helps automatically adjust the number of EC2 instances according to the needs of the application. ASG can automatically scale up (scale out) when traffic increases, or scale down (scale in) when traffic decreases, helping to optimize resources and reduce costs. It also helps ensure high availability by distributing instances across multiple Availability Zones to maintain continuous operation even if part of the system fails.\nIntroducing Elastic Load Balancer Elastic Load Balancer (ELB) is a service that helps distribute workloads (traffic) evenly across multiple servers or instances to ensure stable system operation and avoid overloading any one server. It helps optimize performance, increase availability, and ensure that if a server fails, traffic will be redirected to other servers without affecting users.\nAWS provides three types of Load Balancers:\nApplication Load Balancer (ALB): Optimized for HTTP/HTTPS traffic, operating at the application layer (Layer 7) Network Load Balancer (NLB): Handles traffic at the transport layer (Layer 4), suitable for applications requiring extremely high performance Gateway Load Balancer (GWLB): Used to deploy and manage virtual network devices In this tutorial, we will use Application Load Balancer (ALB) to optimize HTTP/HTTPS traffic.\nIntroducing ElastiCache This service may be expensive, please consider before using.\nElastiCache is an AWS service that allows us to create a Memcached or Redis cluster easily instead of having to install and configure many things ourselves.\nAWS ElastiCache will cover the following for us:\nInstallation: when we create an ElastiCache, AWS will automatically install the necessary things for Memcached and Redis below it, we just need to wait for it to finish installing and use it.\nAdministration: we don\u0026rsquo;t need to worry about the system admin\u0026rsquo;s work for an ElastiCache, AWS will do it for us.\nMonitoring: ElastiCache will push its metrics to CloudWatch.\nBackups: AWS has an option for us to automatically backup cache data (redis only).\nNotification Services 1. Amazon Cloudtrail\nAWS CloudTrail is an Amazon Web Services (AWS) service that records activity in your AWS account, including actions taken by users, roles, or AWS services. It acts as an auditing and monitoring tool, recording events as logs, allowing users to review activity history, analyze risks, and ensure regulatory compliance.\n2. Amazon Cloudwatch\nAmazon CloudWatch is a monitoring and management service that provides actionable data and insights for AWS infrastructure resources and applications, hybrid applications, and on-premises applications. You can collect and access all performance and operational data in the form of logs and metrics in one platform, instead of monitoring them individually (server, network, or database). CloudWatch enables you to monitor end-to-end (applications, infrastructure, and services) and leverage alerts, logs, and event data to automate actions and reduce Mean Time To Resolution (MTTR). This service frees up critical resources and allows you to focus on building applications and business value.\n3. Simple Notification Service(AWS SNS)\nAWS SNS (Simple Notification Service) is a messaging service from Amazon Web Services (AWS) that allows developers to send notifications to subscribers or other applications. It operates on a publish/subscribe model, where publishers send messages to topics, and subscribers receive notifications from topics they are interested in.\n4. Amazon Simple Queue Service(AWS SQS)\nAWS SQS, or Amazon Simple Queue Service, is a fully managed, distributed message queuing service provided by AWS that enables applications and distributed systems to communicate with each other in a flexible and reliable way. SQS helps decouple application components, allowing them to operate independently and increase scalability and fault tolerance.\nMain content Preparation Install Nestjs backend for EC2 Frontend Deployment Service Configuration Clean up resources "
},
{
	"uri": "//localhost:1313/1-create-new-aws-account/1.1-set-up-vpc-and-subnet/",
	"title": "Initialize VPC and Subnet",
	"tags": [],
	"description": "",
	"content": "View AWS account identifiers Create VPC Go to AWS Management Console. Find VPC\nSelect VPC\nIn the VPC interface Select Your VPCs\nSelect Create VPC\nOptions in VPC Wizard Select VPC and more Fill in the VPC name Enter CIDR: 192.168.0.0/16 Select the number of public/private subnets: 2 Select Create VPC "
},
{
	"uri": "//localhost:1313/2-mfa-setup-for-aws-user-root/2.1-setup-ec2-instance/",
	"title": "Launch EC2 Instance",
	"tags": [],
	"description": "",
	"content": "Create EC2 Instance Go to AWS Management Console:\nSearch for EC2 Select EC2 In the EC2 interface:\nSelect Launch instances Configure basic information Name the instance, enter ecourse-backend.\nSelect AMI, select Ubuntu\nIn Instance type, select t2.micro You should choose Instance types belonging to Free tier eligible to avoid fees!!!\nIn Key pair(login), select the key pair just created in 1.3 In Network settings, select Select existing security group. Select the Security group created in 1.2 Select Launch instance "
},
{
	"uri": "//localhost:1313/1-create-new-aws-account/",
	"title": "Preparation Steps",
	"tags": [],
	"description": "",
	"content": "Content:\nPrepare VPC and Subnet Create Security Group for EC2 Create Security Group for Database Instance Initialize EC2 Instance "
},
{
	"uri": "//localhost:1313/3-config-service-hosting-front-end/3.1-config-s3-bucket/",
	"title": "S3 Bucket Configuration",
	"tags": [],
	"description": "",
	"content": " Go to AWS Console Search for S3 Select and the S3 interface will appear. Click Create Bucket At the Bucket initialization interface At Bucket name, name it ecourse-frontend.\nAt Object Ownership, select ACLs disable.\nUncheck Block all public access.\nBucket Versioning. select disable.\nOther items can be kept as is, then select Create Bucket\nAfter creating Bucket, we need to enable Static Website Hosting Click on the bucket just created. Go to the Properties tab. Scroll down to the Static website hosting section → click Edit. Select Enable. Index document: index.html Error document: error.html (if available, or leave blank) Click Save changes. Configure Bucket policy Go to the Permissions tab of bucket.\nScroll down to the Bucket policy section, click Edit.\nPaste the following:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PublicReadGetObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::ecourse-frontend/*\u0026#34; } ] } Then click Save changes Upload the folder and frontend files to the Bucket Go to the Objects tab.\nClick Upload → Add files or Add folder.\nSelect all frontend files/folders (HTML, CSS, JS, img, \u0026hellip;).\nClick Upload. When uploading, you should upload all the sub-files in the parent folder of the frontend project, to avoid errors such as not finding the index.html or error.html file.\nCheck the website Go back to the Properties tab, scroll down to the Static website hosting section.\nCopy Bucket website endpoint and open it on the browser.\nIf you see the website appear, it is successful!\n"
},
{
	"uri": "//localhost:1313/3-config-service-hosting-front-end/3.2-config-cloudfront/",
	"title": "Cloudfront Configuration",
	"tags": [],
	"description": "",
	"content": " In the S3 bucket interface Select Permissions Currently, the Block all public access function is Off because we turned it on and off in the previous section Select Edit Select Block all public access Select Save changes Another window appears to confirm the edit, fill in confirm Select confirm In the search bar, search for Cloudfront and select it After the Cloudfront interface appears, select Create a CloudFront distribution. Specify the following settings for the distribution: In the Distribution name field, enter the name cloudfront-ecourse.\nDecripstion, you can omit it or fill in the description.\nSelect Single website or app.\nSelect Next.\nSelect Amazon S3 for the Origin type field In the Origin S3 field, select the S3 bucket you created. In Setting, check Allow private S3 access to Cloudfront In Origin setting, select Use recommended origin setting, then select Next In Enable security, select Do not enable security protections Check the information again and select Create distribution Connect to S3 bucket After creating, switch to the Origin tab and select Edit\nSelect Use website endpoint\nIn the Origin domain field, select the S3 bucket you created.\nOrigin access field, select Origin access control setting\nOrigin access control section, select e-course-OAC Next, a notification board appears, select Copy policy, then click go to S3 bucket permissions to edit policy (usually it will be automatically edited). Finally, select Create origin Update new content Every time you update new content on S3 bucket, to have Cloudfront also update, go to the invalidation tab, select Create invalidation. In Add object path, write / to update all new content on the bucket. Then, select Create invalidation Check the website To check if the website is active on Cloudfront or not, select the Distribution just created, switch to the General tab, copy the Distribution domain name and run it on the browser. "
},
{
	"uri": "//localhost:1313/1-create-new-aws-account/1.2-create-security-group-for-ec2/",
	"title": "Create Security Group for EC2",
	"tags": [],
	"description": "",
	"content": "Create Security Group for EC2 Create VPC Security group for Amazon EC2 In the VPC interface Select Security Group Select Create security group Proceed to configure Security group name, enter Ecourse-SG Description, enter Security Group for Ecourse Select VPC created Configure Inbound rule To add a rule, select Add rule Custom TCP select port 3000 SSH port 22 used to connect to local machine. Source select My IP HTTP port 80 and source is Anywhere IPv4 HTTPS port 443 and source is Anywhere IPv4 Select Create security group "
},
{
	"uri": "//localhost:1313/2-mfa-setup-for-aws-user-root/2.2-create-elastic-ip/",
	"title": "Initialize Elastic IP",
	"tags": [],
	"description": "",
	"content": "\rElastic IP is intended to provide a public IP for EC2 Instance, which will remain the same regardless of whether EC2 is restarted or not.\nIn the Network \u0026amp; Security section of the EC2 interface:\nSelect Elastic IPs Select Allocate Elastic IP address In the Public IPv4 address pool section, select Amazon\u0026rsquo;s pool of IPv4 addresses.\nIn the Network border group section, select the region you want to use, here is us-east-1.\nSelect Allocate.\nAfter creating, in the Elastic IPs interface:\nSelect the newly created IP, select the Actions button, select Associate Elastic IP address In the Resource type section, select Instance\nSelect the newly created Instance\nSelect Associate\n"
},
{
	"uri": "//localhost:1313/2-mfa-setup-for-aws-user-root/",
	"title": "Install Nestjs backend for EC2",
	"tags": [],
	"description": "",
	"content": "To deploy the backend effectively on AWS, we use Amazon EC2 which is one of the cores of AWS. The great features it brings:\nAmazon EC2 works similar to traditional virtual servers or physical servers, but with the ability to initialize quickly, scale resources flexibly and manage simply. Virtual servers divide physical servers into many virtual servers, helping to optimize the use of hardware resources. Amazon EC2 supports a variety of workloads such as: web hosting, applications, databases, authentication services and any task that a regular server can perform.\n"
},
{
	"uri": "//localhost:1313/1-create-new-aws-account/1.3-create-key-pair/",
	"title": "Create Key Pair",
	"tags": [],
	"description": "",
	"content": "In the Network \u0026amp; Security section of the EC2 interface:\nSelect Key Pairs Select Create key pair In the initialization interface:\nIn the Name section, set it to ecourse-key In the Key pair type section, select RSA In the Private key file format section, select .pem Scroll down to the bottom of the page and select Create key pair Key pair is required when initializing EC2.\n"
},
{
	"uri": "//localhost:1313/2-mfa-setup-for-aws-user-root/2.3-config-ec2-instance/",
	"title": "EC2 Instance Configuration and Backend Deployment",
	"tags": [],
	"description": "",
	"content": "Open CMD: Enter the following command:\nAWS Configure AWS Access Key ID: enter Key ID AWs Secret Access Key ID: enter Secret Key ID Default region name: select region, here is us-east-1 Default output format: enter json Ssh to EC2 with the command ssh -i \u0026#34;C:\\path\\to\\key.pem\u0026#34; ubuntu@[EC2-PUBLIC-IP] Replace C:\\path\\to\\ecourse-key.pem with the actual path to the key file.\nReplace [EC2-PUBLIC-IP] with EC2\u0026rsquo;s public IP.\nAfter SSH is successful, run the following commands:\n# Update system sudo apt update \u0026amp;\u0026amp; sudo apt upgrade -y # Install Node.js 18.x curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash - sudo apt-get install -y nodejs # Install PM2 (process manager) sudo npm install -g pm2 # Install Nginx (web server) sudo apt install nginx -y # Install Git sudo apt install git -y # Check the installation node --version npm --version After installing the necessary paths, we will clone the back end project on git to prepare for deployment to EC2.\nrun the following commands:\n# Clone your backend repository git clone [your-backend-repo-url] cd [your-backend-directory] # Install dependencies npm install # Create environment file cat \u0026gt; .env \u0026lt;\u0026lt; EOF MONGODB_URI=mongodb+srv://ecourse_user:[password]@ecourse-cluster.xxxxx.mongodb.net/ecourse PORT=3000 NODE_ENV=production JWT_SECRET=[your-jwt-secret] EOF Replace [your-backend-repo-url] with the backend repository URL. The link \u0026ldquo;MONGODB_URI\u0026rdquo; has been created in section 1.4, please review. Replace [your-jwt-secret] with the secret key for JWT, located in the back end\u0026rsquo;s .env file. After cloning the project, continue running the following commands:\n# Build application npm run build # Start with PM2 pm2 start dist/main.js --name \u0026#34;ecourse-backend\u0026#34; # Save PM2 configuration pm2 save pm2 startups Then, create Nginx Configuration file\nsudo nano /etc/nginx/sites-available/ecourse Enter the following code:\nserver { listen 80; server_name [EC2_Public_IP]; # Redirect all HTTP to HTTPS return 301 https://$host$request_uri; } server { listen 443 ssl; server_name [EC2_Public_IP]; ssl_certificate /etc/ssl/certs/selfsigned.crt; ssl_certificate_key /etc/ssl/private/selfsigned.key; location / { proxy_pass http://localhost:3000; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#39;upgrade\u0026#39;; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_cache_bypass $http_upgrade; } } Replace [EC2-PUBLIC-IP] with EC2\u0026rsquo;s public IP. Continue running this command to create Ssl needed when deploying front end to Cloudfront because EC2 runs through HTTP method, while Cloudfront runs through HTTPS method:\nsudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 \\ -keyout /etc/ssl/private/selfsigned.key \\ -out /etc/ssl/certs/selfsigned.crt Note: the above command only creates self-signed certificate for development. The best solution: Register a domain and point it to EC2 IP. Install free SSL with Let\u0026rsquo;s Encrypt for that domain. Then, the frontend calls API via https://api.yourdomain.com/\u0026hellip; is the most standard, without security warnings.\nAfter creating the Nginx file, reload it with the command:\nsudo nginx -t sudo systemctl reload nginx After running, test with Postman to check if the backend api is working:\n"
},
{
	"uri": "//localhost:1313/3-config-service-hosting-front-end/",
	"title": "Frontend Deployment Service Configuration",
	"tags": [],
	"description": "",
	"content": "We will use 2 popular services for static website deployment, S3 bucket and Cloudfront with the following features:\nWith S3 bucket:\nS3 is built to meet the requirements of customers of all sizes and industries, who can use this service to store and protect any amount of data.\nS3 can be used for many use cases such as data warehouse, website, mobile application, backup and restore, storage, enterprise application, IoT device and big data analysis. Additionally, Amazon S3 provides easy-to-use management features that help you organize your data and configure access controls to meet your specific business, organizational, and compliance requirements.\nAmazon S3 is designed to provide 99.999999999% (11 9’s) durability and stores data for millions of applications for companies worldwide.\nWith Cloudfront:\nGlobal CDN: CloudFront has a network of edge locations around the world, delivering content closer to users, reducing page load times and improving user experience.\nStatic and dynamic content delivery: CloudFront supports both static content (e.g. images, CSS, JavaScript) and dynamic content (e.g. dynamically generated web pages).\nIntegration with AWS: CloudFront integrates well with other AWS services such as Amazon S3, Amazon EC2, making it easy for companies already using AWS to deploy and manage CDN.\nSecurity: CloudFront provides security features such as SSL/TLS encryption, access control, and integration with AWS Shield to protect against DDoS attacks.\nCost optimization: CloudFront helps optimize costs by offloading origin servers, reducing bandwidth, and providing flexible pricing options.\nOther features: CloudFront also supports features such as video delivery, cache management, and geo-restricted access.\n"
},
{
	"uri": "//localhost:1313/4-automate-with-asg/",
	"title": "Account Authentication Support",
	"tags": [],
	"description": "",
	"content": "Content:\nCheck the information Create a support case with AWS Support During the AWS account creation process, at the contact phone number verification step, sometimes there will be a situation where no SMS or calls from AWS will be received. In that case, follow these steps to complete the account information verification:\nCheck the information First, double-check your account information and make sure it\u0026rsquo;s entered correctly:\nYou have entered the phone number information and selected the correct international area code to receive the call. If you use a mobile phone, check your phone to make sure you are still within range to receive calls. Payment method information has been entered correctly. Make sure that the phone number you provide in your AWS account is reachable.\nCreate a support case with AWS Support After checking that the information is correct but still has not received the verification call, AWS Support will assist you to activate your account manually.\nGo to the AWS Support console, select Create case. Select Account and billing support and enter the support information: Type: select Account. Category: select Activation. Subject: briefly write down your situation (eg Did not receive an SMS message or call for verification) Description: Provide details of the situation encountered and information about the time you need support to activate the account. Attachments: Attach an image describing the authentication step you are facing. Under Contact options, select Chat under Contact methods. Select Submit. 5. The AWS Support team will contact and assist in activating your account.\nYou can create a support request with AWS Support even if your account is not activated.\n"
},
{
	"uri": "//localhost:1313/1-create-new-aws-account/1.4-create-mongodb-database/",
	"title": "Configure database with MongoDB",
	"tags": [],
	"description": "",
	"content": "Cluster Configuration Account Configuration Access MongoDB homepage: MongoDB Create Mongo DB account After creating the account, on the main interface select Cluster Select Build a Cluster Cluster Configuration Select Cluster type: select Free Select Name: name appropriately, or leave the default as Cluster0 Select Provider: Check the AWS box Select Region: Select Region along with Region of EC2 and other services on AWS to avoid problems Check the information again, and select Create Deployment Create Cluster connection After completing the Cluster configuration, we come to the step of creating CLuster connection. On the Set up connection page, after granting permissions, the configurations can be left as default Go to the Choose a connection method page, in the Connect to your application section, select Drivers In section 3. , copy the link to the Cluster, in the form \u0026ldquo;mongodb+srv://\u0026lt;db_username\u0026gt;:\u0026lt;db_password\u0026gt;@cluster0\u0026hellip;\u0026rdquo;, replace \u0026lt;db_username\u0026gt; and \u0026lt;db_password\u0026gt; with username and password on the Set up connection page above. We need this link to connect to the database and EC2. "
},
{
	"uri": "//localhost:1313/5-monitoring/",
	"title": "AWS Database Benchmarking Suite",
	"tags": [],
	"description": "",
	"content": "AWS Database Benchmarking Suite Overview In this workshop, you will build a comprehensive benchmarking suite to test the performance of various AWS database services under different workloads. You will learn how to design and deploy an automated benchmarking system, compare results, detect performance regressions, and create reporting dashboards.\nLearning Objectives Understand major AWS database services (RDS, DynamoDB, Aurora, ElastiCache) Design standardized testing methodology for database performance Build automated benchmark execution system Create result comparison tools and regression detection Design reporting dashboard Write best practices documentation Prerequisites Basic understanding of AWS services (EC2, IAM, CloudWatch) Knowledge of database concepts Experience with Python or Node.js Understanding of performance testing concepts Estimated Time Lab 5.1: 30 minutes - Setup environment and infrastructure Lab 5.2: 45 minutes - Design benchmark methodology Lab 5.3: 60 minutes - Build automated testing framework Lab 5.4: 45 minutes - Create comparison tools and regression detection Lab 5.5: 30 minutes - Build reporting dashboard Lab 5.6: 30 minutes - Write best practices documentation Estimated Cost RDS instances: ~$50-100 (depending on instance type and usage time) DynamoDB: ~$10-20 (for testing workload) EC2 instances: ~$20-40 (for benchmark runner) CloudWatch: ~$5-10 Total: ~$85-170 for entire workshop Important Note: This workshop will create AWS resources that incur costs. Please ensure to delete all resources after completion to avoid unnecessary charges.\nMain Content Setup Infrastructure and Environment Design Benchmark Methodology Build Automated Testing Framework Create Comparison Tools and Regression Detection Build Reporting Dashboard Write Best Practices Documentation Overall Architecture graph TD\rA[Benchmark Runner] --\u0026gt; B[RDS MySQL]\rA --\u0026gt; C[RDS PostgreSQL]\rA --\u0026gt; D[DynamoDB]\rA --\u0026gt; E[ElastiCache Redis]\rA --\u0026gt; F[Aurora]\rG[CloudWatch] --\u0026gt; A\rH[Results Storage] --\u0026gt; A\rI[Dashboard] --\u0026gt; H\rJ[Comparison Engine] --\u0026gt; H AWS Services to be used EC2: Benchmark runner instances RDS: MySQL, PostgreSQL, Aurora databases DynamoDB: NoSQL database testing ElastiCache: Redis caching layer CloudWatch: Monitoring and metrics S3: Store benchmark results Lambda: Automated cleanup and processing IAM: Security and permissions "
},
{
	"uri": "//localhost:1313/6-elasticache/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]