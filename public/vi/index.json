[
{
	"uri": "//localhost:1313/vi/",
	"title": "Triển khai trang web nestjs api lên AWS",
	"tags": [],
	"description": "",
	"content": "Triển khai website Nestjs lên AWS Tổng quan Trong bài lap này, bạn sẽ được hướng dẫn cách triển khai một trang web chạy backend API Nestjs lên nền tảng của AWS. Với các dịch vụ hỗ trợ một cách tối ưu như EC2, VPC, S3, Cloudfront,\u0026hellip;, trang web của bạn sẽ hoạt động một cách nhanh chóng, phù hợp với yêu cầu khắt khe của người dùng. Giới thiệu Amazon Elastic Compute Cloud (EC2) Amazon EC2 là dịch vụ cung cấp khả năng điện toán đám mây có thể thay đổi kích thước được trên AWS. Một số đặc điểm chính:\nAmazon EC2 hoạt động tương tự như máy chủ ảo hoặc máy chủ vật lý truyền thống, nhưng với khả năng khởi tạo nhanh chóng, co giãn tài nguyên linh hoạt và quản lý đơn giản.\nMáy chủ ảo chia nhỏ máy chủ vật lý thành nhiều máy chủ ảo, giúp tối ưu hóa việc sử dụng tài nguyên phần cứng.\nAmazon EC2 hỗ trợ đa dạng các workload như: lưu trữ web, ứng dụng, cơ sở dữ liệu, dịch vụ xác thực và bất kỳ tác vụ nào mà máy chủ thông thường có thể thực hiện.\nGiới thiệu Amazon Virtual Private Cloud (Amazon VPC) Amazon VPC là dịch vụ mạng ảo tùy chỉnh nằm trong AWS Cloud, cho phép bạn tạo một môi trường mạng riêng biệt và hoàn toàn tách biệt với thế giới bên ngoài. Khái niệm này tương tự như việc thiết kế và triển khai một mạng độc lập trong trung tâm dữ liệu on-premise truyền thống. Tính năng chính:\nKiểm soát hoàn toàn môi trường mạng ảo Khởi tạo và quản lý tài nguyên AWS Tùy chỉnh phạm vi địa chỉ IP và phân đoạn mạng Cấu hình định tuyến và kết nối mạng linh hoạt Hỗ trợ đầy đủ IPv4 và IPv6 Giới thiệu Amazon Simple Storage Service (Amazon S3) Amazon Simple Storage Service (Amazon S3) là một dịch vụ lưu trữ dạng đối tượng cung cấp khả năng mở rộng theo yêu cầu sử dụng, đảm bảo tính khả dụng của dữ liệu, độ bảo mật, và hiệu năng ở mức cao nhất.\nS3 được xây dựng để đáp ứng yêu cầu của khách hàng thuộc mọi quy mô và ngành nghề, đều có thể dùng dịch vụ này để lưu trữ và bảo vệ bất kỳ lượng dữ liệu nào.\nS3 có thể được dùng cho nhiều trường hợp sử dụng như kho dữ liệu (data warehouse), trang web, ứng dụng di động, sao lưu và khôi phục, lưu trữ, ứng dụng doanh nghiệp, thiết bị IoT và phân tích dữ liệu lớn. Ngoài ra, Amazon S3 còn cung cấp các tính năng quản lý dễ sử dụng, giúp bạn có thể tổ chức dữ liệu và cấu hình các biện pháp kiểm soát truy cập để đáp ứng yêu cầu cụ thể của doanh nghiệp, tổ chức và yêu cầu về tuân thủ.\nAmazon S3 được thiết kế để đảm bảo độ bền 99,999999999% (11 9’s) và lưu trữ dữ liệu của hàng triệu ứng dụng cho các công ty trên toàn thế giới.\nGiới thiệu Amazon Cloudfront Amazon CloudFront là một dịch vụ mạng phân phối nội dung (CDN) của Amazon Web Services (AWS). Nó giúp tăng tốc độ phân phối nội dung web, video, ứng dụng và API đến người dùng trên toàn cầu bằng cách phân phối nội dung từ các vị trí trung gian (edge locations) gần người dùng nhất, giảm độ trễ và cải thiện hiệu suất. Tính năng chính:\nCDN toàn cầu: CloudFront có mạng lưới các điểm hiện diện (edge locations) trên toàn thế giới, cho phép phân phối nội dung gần hơn với người dùng, giảm thời gian tải trang và cải thiện trải nghiệm người dùng. Phân phối nội dung tĩnh và động: CloudFront hỗ trợ cả nội dung tĩnh (ví dụ: hình ảnh, CSS, JavaScript) và nội dung động (ví dụ: trang web được tạo động). Tích hợp với AWS: CloudFront tích hợp tốt với các dịch vụ AWS khác như Amazon S3, Amazon EC2, giúp các công ty đã sử dụng AWS có thể dễ dàng triển khai và quản lý CDN. Bảo mật: CloudFront cung cấp các tính năng bảo mật như mã hóa SSL/TLS, kiểm soát truy cập và tích hợp với AWS Shield để bảo vệ chống lại các cuộc tấn công DDoS. Tối ưu chi phí: CloudFront giúp tối ưu hóa chi phí bằng cách giảm tải cho các máy chủ gốc, giảm băng thông và cung cấp các tùy chọn định giá linh hoạt. Tính năng khác: CloudFront còn hỗ trợ các tính năng như phân phối video, quản lý cache, và giới hạn truy cập theo khu vực địa lý. Giới thiệu AWS Cognito AWS Cognito cho phép chúng ta dễ dàng xây dựng luồng đăng nhập, đăng ký, xác minh email, đổi mật khẩu, đặt lại mật khẩu, v.v., thay vì phải tự xây dựng DB cho người dùng và thực hiện nhiều thao tác như JWT, băm mật khẩu, gửi email xác minh,\u0026hellip; Điều này giúp bạn tập trung phát triển các tính năng khác của ứng dụng. Người dùng có thể đăng nhập trực tiếp bằng tên người dùng và mật khẩu hoặc thông qua bên thứ ba như Facebook, Amazon, Google hoặc Apple. Hai thành phần chính của Amazon Cognito là nhóm người dùng và nhóm danh tính:\nNhóm người dùng : thư mục người dùng cung cấp tùy chọn đăng ký và đăng nhập cho người dùng web và ứng dụng di động của bạn. Sau khi đăng nhập bằng nhóm người dùng, người dùng ứng dụng có thể truy cập các tài nguyên mà ứng dụng cho phép. Nhóm danh tính : cấp cho người dùng của bạn quyền truy cập vào các dịch vụ AWS khác. Giới thiệu Amazon EC2 Auto Scaling Group 1. Tại sao cần sử dụng Auto scaling group?\nKhi ứng dụng của chúng ta đưa vào hoạt động, lượng người truy cập sẽ thay đổi theo thời gian, do đó chúng ta cần thường xuyên thay đổi (scaling) lượng instance nhằm nâng cao tính sẵn sàng và tiết kiệm chi phí. Để tự động hóa và linh hoạt trong công việc scaling, chúng ta sẽ có giải pháp là Auto Scaling Group.\n2. Sơ lược về Auto Scaling Group\nAmazon EC2 Auto Scaling Group (ASG) giúp tự động điều chỉnh số lượng EC2 instances theo nhu cầu của ứng dụng. ASG có thể tự động mở rộng (scale out) khi lưu lượng tăng, hoặc thu nhỏ (scale in) khi lưu lượng giảm, giúp tối ưu hóa tài nguyên và giảm chi phí. Nó cũng giúp đảm bảo tính sẵn sàng cao bằng cách phân phối instances qua nhiều Availability Zones để duy trì hoạt động liên tục ngay cả khi một phần của hệ thống gặp sự cố.\nGiới thiệu Elastic Load Balancer Elastic Load Balancer (ELB) là một dịch vụ giúp phân phối đều tải công việc (traffic) đến nhiều máy chủ hoặc instances để đảm bảo hệ thống hoạt động ổn định và tránh quá tải cho bất kỳ một máy chủ nào. Nó giúp tối ưu hiệu suất, tăng tính sẵn sàng và đảm bảo rằng nếu một máy chủ gặp sự cố, lưu lượng sẽ được chuyển hướng tới các máy chủ khác mà không ảnh hưởng đến người dùng.\nAWS cung cấp ba loại Load Balancer:\nApplication Load Balancer (ALB): Tối ưu cho HTTP/HTTPS traffic, hoạt động ở tầng ứng dụng (Layer 7) Network Load Balancer (NLB): Xử lý traffic ở tầng vận chuyển (Layer 4), phù hợp cho các ứng dụng yêu cầu hiệu suất cực cao Gateway Load Balancer (GWLB): Dùng để triển khai và quản lý các thiết bị mạng ảo Trong bài hướng dẫn này, chúng ta sẽ sử dụng Application Load Balancer (ALB) để tối ưu HTTP/HTTPS traffic.\nGiới thiệu ElastiCache Service này có thể tính phí cao, vui lòng cân nhắc trước khi sử dụng.\nElastiCache là một dịch vụ của AWS mà cho phép ta tạo một clusters Memcached hoặc Redis một cách dễ dàng thay vì ta phải tự cài đặt và cấu hình nhiều thứ. AWS ElastiCache sẽ cover cho ta nhứng thứ sau:\nInstallation: khi ta tạo một ElastiCache thì AWS sẽ tự động cài đặt những thứ cần thiết cho Memcached và Redis ở bên dưới của nó, ta chỉ cần đợi nó cài xong và xài. Administration: những vấn đề liên quan tới công việc của system admin cho một ElastiCache thì ta không cần phải quan tâm, AWS làm cho ta. Monitoring: ElastiCache sẽ push metrics của nó lên trên CloudWatch. Backups: AWS có option cho ta tự động backup dữ liệu cache (redis only). Các dịch vụ thông báo 1. Amazon Cloudtrail\nAWS CloudTrail là một dịch vụ của Amazon Web Services (AWS) giúp ghi lại hoạt động của tài khoản AWS của bạn, bao gồm cả các hành động được thực hiện bởi người dùng, vai trò hoặc dịch vụ AWS. Nó hoạt động như một công cụ kiểm toán và giám sát, ghi lại các sự kiện dưới dạng nhật ký, cho phép người dùng xem lại lịch sử hoạt động, phân tích rủi ro và đảm bảo tuân thủ các quy định.\n2. Amazon Cloudwatch\nAmazon CloudWatch là dịch vụ theo dõi và quản lý cung cấp dữ liệu và thông tin định hướng hành động cho tài nguyên cơ sở hạ tầng và ứng dụng AWS, ứng dụng hybrid cũng như ứng dụng on-premises. Bạn có thể thu thập và truy cập tất cả dữ liệu về hiệu năng và hoạt động dưới hình thức logs và metrics trong cùng một nền tảng, thay vì theo dõi riêng lẻ (máy chủ, mạng hoặc cơ sở dữ liệu). CloudWatch cho phép bạn theo dõi end-to-end (ứng dụng, cơ sở hạ tầng và dịch vụ) và tận dụng cảnh báo, logs và dữ liệu sự kiện để tự động hóa các hành động và giảm Mean Time To Resolution (MTTR). Dịch vụ này giúp bạn giải phóng tài nguyên quan trọng và tập trung vào việc xây dựng các ứng dụng và giá trị kinh doanh.\n3. Simple Notification Service(AWS SNS)\nAWS SNS (Simple Notification Service) là một dịch vụ nhắn tin của Amazon Web Services (AWS) cho phép các nhà phát triển gửi thông báo (notifications) đến các thuê bao (subscribers) hoặc các ứng dụng khác. Nó hoạt động theo mô hình xuất bản/đăng ký (publish/subscribe), nơi các nhà xuất bản (publishers) gửi tin nhắn đến các chủ đề (topics), và các người đăng ký (subscribers) nhận thông báo từ các chủ đề mà họ quan tâm.\n4. Amazon Simple Queue Service(AWS SQS)\nAWS SQS, hay Amazon Simple Queue Service, là một dịch vụ hàng đợi tin nhắn phân tán, được quản lý hoàn toàn bởi AWS, giúp các ứng dụng và hệ thống phân tán có thể giao tiếp với nhau một cách linh hoạt và đáng tin cậy. SQS giúp tách rời các thành phần của ứng dụng, cho phép chúng hoạt động độc lập và tăng khả năng mở rộng, chịu lỗi.\nNội dung chính Chuẩn bị Thực hiện tạo Auto Scaling cho Nestjs Instance Khởi tạo Cloudfront cho Web Server Dọn dẹp tài nguyên "
},
{
	"uri": "//localhost:1313/vi/1-create-new-aws-account/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "Nội dung:\nChuẩn bị VPC và Subnet Tạo Security Group cho EC2 Tạo Security Group cho Database Instance Khởi tạo EC2 Instance "
},
{
	"uri": "//localhost:1313/vi/2-mfa-setup-for-aws-user-root/",
	"title": "Cài đặt backend Nodejs cho EC2",
	"tags": [],
	"description": "",
	"content": "Hướng dẫn Thiết lập Multi-Factor Authentication (MFA) Trong quy trình bảo mật, việc sử dụng Multi-Factor Authentication (MFA) rất quan trọng. Trong bước này, bạn sẽ sử dụng ba loại thiết bị MFA khác nhau để tăng cường tính bảo mật.\nThiết bị MFA ảo trên smartphone Một cách phổ biến để thực hiện MFA là sử dụng các ứng dụng MFA trên điện thoại thông minh. Có ba ứng dụng phổ biến mà bạn có thể sử dụng:\nMicrosoft Authenticator Google Authenticator Okta Verify Để cài đặt MFA với các ứng dụng này, bạn cần thực hiện các bước sau:\nTải và cài đặt ứng dụng từ cửa hàng ứng dụng chính thức của hãng phát triển. Theo hướng dẫn trong ứng dụng, thêm tài khoản bảo mật bằng cách quét mã QR hoặc nhập mã cung cấp. Khóa bảo mật U2F cứng Khóa bảo mật U2F (Universal 2nd Factor) cung cấp một lớp bảo mật bổ sung thông qua cổng USB. Để cài đặt khóa bảo mật U2F, bạn cần thực hiện các bước sau:\nMua khóa bảo mật U2F tương thích với hệ thống của bạn. Kết nối khóa vào cổng USB của máy tính. Theo hướng dẫn của hãng sản xuất, thực hiện quá trình đăng ký và cài đặt. Thiết bị MFA phần cứng khác Ngoài các tùy chọn trên, còn có các thiết bị MFA phần cứng khác như khóa bảo mật Gemalto. Để sử dụng các thiết bị này, bạn cần tuân thủ hướng dẫn cụ thể từ nhà sản xuất.\nLiên kết nhanh đến các phần hướng dẫn chi tiết Thiết lập với thiết bị MFA ảo Thiết lập với Khóa Bảo mật U2F Thiết lập với thiết bị MFA phần cứng khác "
},
{
	"uri": "//localhost:1313/vi/2-mfa-setup-for-aws-user-root/2.1-setup-ec2-instance/",
	"title": "Khởi tạo EC2 Instance",
	"tags": [],
	"description": "",
	"content": "Tạo EC2 Instance Truy cập vào AWS Management Console:\nTìm EC2 Chọn EC2 Trong giao diện EC2:\nChọn Launch instances Cấu hình thông tin cơ bản Đặt tên cho instance, nhập ecourse-backend. Chọn AMI, chọn Ubuntu Mục Instance type, chọn t2.micro Bạn nên chọn những Instance type thuộc Free tier eligible để tránh tốn phí!!!\nMục Key pair(login), chọn key pair vừa tạo ở mục 1.3 Mục Network settings, chọn Select existing security group. Chọn Sercurity group đã tạo ở mục 1.2 Chọn Launch ínstance "
},
{
	"uri": "//localhost:1313/vi/1-create-new-aws-account/1.1-set-up-vpc-and-subnet/",
	"title": "Khởi tạo VPC và Subnet",
	"tags": [],
	"description": "",
	"content": "View AWS account identifiers Tạo VPC Truy cập AWS Management Console. Tìm VPC Chọn VPC Trong giao diện VPC Chọn Your VPCs Chọn Create VPC Tùy chọn trong VPC Wizard Chọn VPC and more Điền tên VPC Nhập CIDR: 192.168.0.0/16 Chọn số lượng public/private subnet: 2 Chọn Create VPC "
},
{
	"uri": "//localhost:1313/vi/5-aws-database-benchmarking-suite/5.1-setup-infrastructure/",
	"title": "Thiết lập Infrastructure và Môi trường",
	"tags": [],
	"description": "",
	"content": "Thiết lập Infrastructure và Môi trường Tổng quan Trong lab này, bạn sẽ thiết lập toàn bộ infrastructure cần thiết cho AWS Database Benchmarking Suite. Chúng ta sẽ tạo VPC, security groups, IAM roles, và các database instances cần thiết cho việc testing.\nMục tiêu Tạo VPC và networking infrastructure Thiết lập security groups cho database access Tạo IAM roles và policies Deploy các database instances (RDS, DynamoDB, ElastiCache) Thiết lập CloudWatch monitoring Thời gian: 30 phút Bước 1: Tạo VPC và Networking Đăng nhập vào AWS Console\nTruy cập AWS Console Chọn region gần nhất (ví dụ: ap-southeast-1) Tạo VPC\n# Tạo VPC cho benchmark environment aws ec2 create-vpc \\ --cidr-block 10.0.0.0/16 \\ --tag-specifications \u0026#39;ResourceType=vpc,Tags=[{Key=Name,Value=benchmark-vpc}]\u0026#39; Tạo Subnets\n# Tạo public subnet aws ec2 create-subnet \\ --vpc-id vpc-xxxxxxxxx \\ --cidr-block 10.0.1.0/24 \\ --availability-zone ap-southeast-1a \\ --tag-specifications \u0026#39;ResourceType=subnet,Tags=[{Key=Name,Value=benchmark-public-subnet}]\u0026#39; # Tạo private subnet aws ec2 create-subnet \\ --vpc-id vpc-xxxxxxxxx \\ --cidr-block 10.0.2.0/24 \\ --availability-zone ap-southeast-1b \\ --tag-specifications \u0026#39;ResourceType=subnet,Tags=[{Key=Name,Value=benchmark-private-subnet}]\u0026#39; Bước 2: Thiết lập Security Groups Tạo Security Group cho Database Access\n# Tạo security group cho RDS aws ec2 create-security-group \\ --group-name benchmark-db-sg \\ --description \u0026#34;Security group for database benchmarking\u0026#34; \\ --vpc-id vpc-xxxxxxxxx # Thêm rule cho MySQL/PostgreSQL aws ec2 authorize-security-group-ingress \\ --group-id sg-xxxxxxxxx \\ --protocol tcp \\ --port 3306 \\ --cidr 10.0.0.0/16 aws ec2 authorize-security-group-ingress \\ --group-id sg-xxxxxxxxx \\ --protocol tcp \\ --port 5432 \\ --cidr 10.0.0.0/16 Tạo Security Group cho EC2 Benchmark Runner\n# Tạo security group cho EC2 aws ec2 create-security-group \\ --group-name benchmark-ec2-sg \\ --description \u0026#34;Security group for benchmark runner\u0026#34; \\ --vpc-id vpc-xxxxxxxxx # Thêm SSH access aws ec2 authorize-security-group-ingress \\ --group-id sg-xxxxxxxxx \\ --protocol tcp \\ --port 22 \\ --cidr 0.0.0.0/0 Bước 3: Tạo IAM Roles và Policies Tạo IAM Policy cho Benchmark Runner\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;rds:DescribeDBInstances\u0026#34;, \u0026#34;rds:DescribeDBClusters\u0026#34;, \u0026#34;dynamodb:DescribeTable\u0026#34;, \u0026#34;dynamodb:Scan\u0026#34;, \u0026#34;dynamodb:Query\u0026#34;, \u0026#34;elasticache:DescribeCacheClusters\u0026#34;, \u0026#34;cloudwatch:PutMetricData\u0026#34;, \u0026#34;cloudwatch:GetMetricStatistics\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Tạo IAM Role\n# Tạo role aws iam create-role \\ --role-name BenchmarkRunnerRole \\ --assume-role-policy-document \u0026#39;{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;ec2.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] }\u0026#39; # Attach policy aws iam attach-role-policy \\ --role-name BenchmarkRunnerRole \\ --policy-arn arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore Bước 4: Deploy Database Instances Tạo RDS MySQL Instance\naws rds create-db-instance \\ --db-instance-identifier benchmark-mysql \\ --db-instance-class db.t3.micro \\ --engine mysql \\ --engine-version 8.0.28 \\ --master-username admin \\ --master-user-password YourPassword123! \\ --allocated-storage 20 \\ --vpc-security-group-ids sg-xxxxxxxxx \\ --db-subnet-group-name benchmark-subnet-group \\ --backup-retention-period 7 \\ --deletion-protection Tạo RDS PostgreSQL Instance\naws rds create-db-instance \\ --db-instance-identifier benchmark-postgres \\ --db-instance-class db.t3.micro \\ --engine postgres \\ --engine-version 13.7 \\ --master-username admin \\ --master-user-password YourPassword123! \\ --allocated-storage 20 \\ --vpc-security-group-ids sg-xxxxxxxxx \\ --db-subnet-group-name benchmark-subnet-group \\ --backup-retention-period 7 \\ --deletion-protection Tạo DynamoDB Table\naws dynamodb create-table \\ --table-name benchmark-table \\ --attribute-definitions AttributeName=id,AttributeType=S \\ --key-schema AttributeName=id,KeyType=HASH \\ --billing-mode PAY_PER_REQUEST Tạo ElastiCache Redis Cluster\naws elasticache create-cache-cluster \\ --cache-cluster-id benchmark-redis \\ --engine redis \\ --cache-node-type cache.t3.micro \\ --num-cache-nodes 1 \\ --vpc-security-group-ids sg-xxxxxxxxx \\ --subnet-group-name benchmark-subnet-group Bước 5: Thiết lập CloudWatch Monitoring Tạo CloudWatch Dashboard\naws cloudwatch put-dashboard \\ --dashboard-name BenchmarkDashboard \\ --dashboard-body \u0026#39;{ \u0026#34;widgets\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;metric\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;metrics\u0026#34;: [ [\u0026#34;AWS/RDS\u0026#34;, \u0026#34;CPUUtilization\u0026#34;, \u0026#34;DBInstanceIdentifier\u0026#34;, \u0026#34;benchmark-mysql\u0026#34;], [\u0026#34;AWS/RDS\u0026#34;, \u0026#34;DatabaseConnections\u0026#34;, \u0026#34;DBInstanceIdentifier\u0026#34;, \u0026#34;benchmark-mysql\u0026#34;] ], \u0026#34;period\u0026#34;: 300, \u0026#34;stat\u0026#34;: \u0026#34;Average\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;RDS MySQL Metrics\u0026#34; } } ] }\u0026#39; Tạo CloudWatch Alarms\n# CPU Utilization Alarm aws cloudwatch put-metric-alarm \\ --alarm-name benchmark-cpu-alarm \\ --alarm-description \u0026#34;CPU utilization high\u0026#34; \\ --metric-name CPUUtilization \\ --namespace AWS/RDS \\ --statistic Average \\ --period 300 \\ --threshold 80 \\ --comparison-operator GreaterThanThreshold \\ --evaluation-periods 2 \\ --dimensions Name=DBInstanceIdentifier,Value=benchmark-mysql Bước 6: Tạo S3 Bucket cho Results # Tạo S3 bucket cho benchmark results aws s3 mb s3://benchmark-results-$(date +%s) \\ --region ap-southeast-1 # Tạo bucket policy aws s3api put-bucket-policy \\ --bucket benchmark-results-xxxxxxxxx \\ --policy \u0026#39;{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowBenchmarkRunner\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::ACCOUNT-ID:role/BenchmarkRunnerRole\u0026#34; }, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::benchmark-results-xxxxxxxxx\u0026#34;, \u0026#34;arn:aws:s3:::benchmark-results-xxxxxxxxx/*\u0026#34; ] } ] }\u0026#39; Bước 7: Tạo EC2 Instance cho Benchmark Runner # Tạo EC2 instance aws ec2 run-instances \\ --image-id ami-xxxxxxxxx \\ --count 1 \\ --instance-type t3.medium \\ --key-name your-key-pair \\ --security-group-ids sg-xxxxxxxxx \\ --subnet-id subnet-xxxxxxxxx \\ --iam-instance-profile Name=BenchmarkRunnerRole \\ --tag-specifications \u0026#39;ResourceType=instance,Tags=[{Key=Name,Value=benchmark-runner}]\u0026#39; Kiểm tra và Validation Kiểm tra tất cả resources đã được tạo\n# Kiểm tra VPC aws ec2 describe-vpcs --filters \u0026#34;Name=tag:Name,Values=benchmark-vpc\u0026#34; # Kiểm tra RDS instances aws rds describe-db-instances --db-instance-identifier benchmark-mysql aws rds describe-db-instances --db-instance-identifier benchmark-postgres # Kiểm tra DynamoDB table aws dynamodb describe-table --table-name benchmark-table # Kiểm tra ElastiCache cluster aws elasticache describe-cache-clusters --cache-cluster-id benchmark-redis Test connectivity\n# SSH vào EC2 instance ssh -i your-key.pem ec2-user@your-ec2-ip # Test connection đến MySQL mysql -h benchmark-mysql.xxxxxxxxx.ap-southeast-1.rds.amazonaws.com -u admin -p # Test connection đến PostgreSQL psql -h benchmark-postgres.xxxxxxxxx.ap-southeast-1.rds.amazonaws.com -U admin -d postgres Cleanup (Quan trọng!) Sau khi hoàn thành workshop, hãy xóa tất cả resources:\n# Xóa EC2 instance aws ec2 terminate-instances --instance-ids i-xxxxxxxxx # Xóa RDS instances aws rds delete-db-instance --db-instance-identifier benchmark-mysql --skip-final-snapshot aws rds delete-db-instance --db-instance-identifier benchmark-postgres --skip-final-snapshot # Xóa DynamoDB table aws dynamodb delete-table --table-name benchmark-table # Xóa ElastiCache cluster aws elasticache delete-cache-cluster --cache-cluster-id benchmark-redis # Xóa S3 bucket aws s3 rb s3://benchmark-results-xxxxxxxxx --force # Xóa VPC aws ec2 delete-vpc --vpc-id vpc-xxxxxxxxx Tóm tắt Trong lab này, bạn đã:\n✅ Tạo VPC và networking infrastructure ✅ Thiết lập security groups ✅ Tạo IAM roles và policies ✅ Deploy các database instances ✅ Thiết lập CloudWatch monitoring ✅ Tạo S3 bucket cho results ✅ Deploy EC2 benchmark runner Bước tiếp theo: Thiết kế Benchmark Methodology\n"
},
{
	"uri": "//localhost:1313/vi/2-mfa-setup-for-aws-user-root/2.2-create-elastic-ip/",
	"title": "Khởi tạo Elastic IP",
	"tags": [],
	"description": "",
	"content": " Elastic IP nhằm mục đích cung cấp một public Ip cho EC2 Instance, nó luôn giữ nguyên dù cho EC2 có khởi động lại hay không.\nTrong mục Network \u0026amp; Security của giao diện EC2:\nChọn Elastic IPs Chọn Allocate Elastic IP address Mục Public IPv4 address pool, chọn Amazon\u0026rsquo;s pool of IPv4 addresses. Mục Network border group, chọn region mà bạn muốn sử dụng, ở đây là us-east-1. Chọn Allocate. Sau khi tạo xong, ở giao diện Elastic IPs:\nChọn Ip vừa tạo, chọn nút Actions, chọn Associate Elastic IP address Ở mục Resource type, chọn Instance Chọn Instance vừa tạo Chọn Associate "
},
{
	"uri": "//localhost:1313/vi/1-create-new-aws-account/1.2-create-security-group-for-ec2/",
	"title": "Tạo Sercurity Group cho EC2",
	"tags": [],
	"description": "",
	"content": "Tạo VPC Security group cho Amazon EC2 Trong giao diện VPC Chọn Security Group Chọn Create security group Tiến hành cấu hình Security group name, nhập Ecourse-SG Description, nhập Security Group for Ecourse Chọn VPC đã tạo Cấu hình Inbound rule Để thêm rule, chọn Add rule Custom TCP chọn port 3000 SSH cổng 22 dùng để kết nối với máy local. Source chọn My IP HTTP cổng 80 và source là Anywhere IPv4 HTTPS cổng 443 và source là Anywhere IPv4 Chọn Create security group "
},
{
	"uri": "//localhost:1313/vi/5-aws-database-benchmarking-suite/5.2-benchmark-methodology/",
	"title": "Thiết kế Benchmark Methodology",
	"tags": [],
	"description": "",
	"content": "Thiết kế Benchmark Methodology Tổng quan Trong lab này, bạn sẽ thiết kế một methodology chuẩn hóa cho việc benchmark các AWS database services. Chúng ta sẽ định nghĩa các workload patterns, metrics cần đo, và cách thức thực hiện tests một cách nhất quán.\nMục tiêu Định nghĩa các workload patterns chuẩn Thiết kế metrics collection framework Tạo test scenarios cho từng database service Thiết lập baseline performance standards Định nghĩa success criteria và thresholds Thời gian: 45 phút Bước 1: Định nghĩa Workload Patterns OLTP (Online Transaction Processing) Workload\n# OLTP Workload Definition oltp_workload = { \u0026#34;name\u0026#34;: \u0026#34;OLTP_Standard\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Standard OLTP workload with read/write operations\u0026#34;, \u0026#34;operations\u0026#34;: { \u0026#34;read_ratio\u0026#34;: 0.7, # 70% reads, 30% writes \u0026#34;batch_size\u0026#34;: 1, # Single record operations \u0026#34;concurrent_users\u0026#34;: [10, 50, 100, 200], \u0026#34;test_duration\u0026#34;: 300 # 5 minutes per test }, \u0026#34;data_patterns\u0026#34;: { \u0026#34;record_size\u0026#34;: \u0026#34;1-10KB\u0026#34;, \u0026#34;indexes\u0026#34;: [\u0026#34;primary_key\u0026#34;, \u0026#34;secondary_indexes\u0026#34;], \u0026#34;relationships\u0026#34;: \u0026#34;normalized\u0026#34; } } OLAP (Online Analytical Processing) Workload\n# OLAP Workload Definition olap_workload = { \u0026#34;name\u0026#34;: \u0026#34;OLAP_Analytics\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Analytical queries with complex joins and aggregations\u0026#34;, \u0026#34;operations\u0026#34;: { \u0026#34;read_ratio\u0026#34;: 0.95, # 95% reads, 5% writes \u0026#34;batch_size\u0026#34;: 1000, # Large batch operations \u0026#34;concurrent_users\u0026#34;: [5, 10, 20], \u0026#34;test_duration\u0026#34;: 600 # 10 minutes per test }, \u0026#34;data_patterns\u0026#34;: { \u0026#34;record_size\u0026#34;: \u0026#34;10-100KB\u0026#34;, \u0026#34;indexes\u0026#34;: [\u0026#34;composite_indexes\u0026#34;, \u0026#34;covering_indexes\u0026#34;], \u0026#34;relationships\u0026#34;: \u0026#34;denormalized\u0026#34; } } NoSQL Workload\n# NoSQL Workload Definition nosql_workload = { \u0026#34;name\u0026#34;: \u0026#34;NoSQL_High_Throughput\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;High-throughput key-value operations\u0026#34;, \u0026#34;operations\u0026#34;: { \u0026#34;read_ratio\u0026#34;: 0.8, # 80% reads, 20% writes \u0026#34;batch_size\u0026#34;: 25, # Batch operations \u0026#34;concurrent_users\u0026#34;: [50, 100, 200, 500], \u0026#34;test_duration\u0026#34;: 300 # 5 minutes per test }, \u0026#34;data_patterns\u0026#34;: { \u0026#34;record_size\u0026#34;: \u0026#34;1-50KB\u0026#34;, \u0026#34;indexes\u0026#34;: [\u0026#34;primary_key\u0026#34;], \u0026#34;relationships\u0026#34;: \u0026#34;document_based\u0026#34; } } Bước 2: Thiết kế Metrics Collection Framework Performance Metrics\n# Core Performance Metrics performance_metrics = { \u0026#34;throughput\u0026#34;: { \u0026#34;operations_per_second\u0026#34;: \u0026#34;float\u0026#34;, \u0026#34;queries_per_second\u0026#34;: \u0026#34;float\u0026#34;, \u0026#34;transactions_per_second\u0026#34;: \u0026#34;float\u0026#34; }, \u0026#34;latency\u0026#34;: { \u0026#34;average_response_time\u0026#34;: \u0026#34;float\u0026#34;, \u0026#34;p50_response_time\u0026#34;: \u0026#34;float\u0026#34;, \u0026#34;p95_response_time\u0026#34;: \u0026#34;float\u0026#34;, \u0026#34;p99_response_time\u0026#34;: \u0026#34;float\u0026#34;, \u0026#34;max_response_time\u0026#34;: \u0026#34;float\u0026#34; }, \u0026#34;resource_utilization\u0026#34;: { \u0026#34;cpu_utilization\u0026#34;: \u0026#34;float\u0026#34;, \u0026#34;memory_utilization\u0026#34;: \u0026#34;float\u0026#34;, \u0026#34;disk_io\u0026#34;: \u0026#34;float\u0026#34;, \u0026#34;network_io\u0026#34;: \u0026#34;float\u0026#34; }, \u0026#34;errors\u0026#34;: { \u0026#34;error_rate\u0026#34;: \u0026#34;float\u0026#34;, \u0026#34;timeout_rate\u0026#34;: \u0026#34;float\u0026#34;, \u0026#34;connection_errors\u0026#34;: \u0026#34;int\u0026#34; } } Cost Metrics\n# Cost Analysis Metrics cost_metrics = { \u0026#34;operational_costs\u0026#34;: { \u0026#34;compute_cost_per_hour\u0026#34;: \u0026#34;float\u0026#34;, \u0026#34;storage_cost_per_gb\u0026#34;: \u0026#34;float\u0026#34;, \u0026#34;network_cost_per_gb\u0026#34;: \u0026#34;float\u0026#34;, \u0026#34;total_cost_per_test\u0026#34;: \u0026#34;float\u0026#34; }, \u0026#34;efficiency_metrics\u0026#34;: { \u0026#34;cost_per_operation\u0026#34;: \u0026#34;float\u0026#34;, \u0026#34;cost_per_1000_queries\u0026#34;: \u0026#34;float\u0026#34;, \u0026#34;cost_performance_ratio\u0026#34;: \u0026#34;float\u0026#34; } } Bước 3: Tạo Test Scenarios cho từng Database Service RDS MySQL Test Scenarios\nmysql_test_scenarios = { \u0026#34;basic_crud\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Basic Create, Read, Update, Delete operations\u0026#34;, \u0026#34;queries\u0026#34;: [ \u0026#34;INSERT INTO users (name, email) VALUES (?, ?)\u0026#34;, \u0026#34;SELECT * FROM users WHERE id = ?\u0026#34;, \u0026#34;UPDATE users SET name = ? WHERE id = ?\u0026#34;, \u0026#34;DELETE FROM users WHERE id = ?\u0026#34; ], \u0026#34;data_size\u0026#34;: \u0026#34;1M records\u0026#34;, \u0026#34;concurrent_connections\u0026#34;: [10, 50, 100] }, \u0026#34;complex_queries\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Complex queries with joins and aggregations\u0026#34;, \u0026#34;queries\u0026#34;: [ \u0026#34;SELECT u.name, COUNT(o.id) FROM users u JOIN orders o ON u.id = o.user_id GROUP BY u.id\u0026#34;, \u0026#34;SELECT category, AVG(price) FROM products GROUP BY category HAVING AVG(price) \u0026gt; 100\u0026#34; ], \u0026#34;data_size\u0026#34;: \u0026#34;10M records\u0026#34;, \u0026#34;concurrent_connections\u0026#34;: [5, 10, 20] }, \u0026#34;bulk_operations\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Bulk insert and batch operations\u0026#34;, \u0026#34;queries\u0026#34;: [ \u0026#34;INSERT INTO products (name, price, category) VALUES (?, ?, ?), (?, ?, ?), ...\u0026#34;, \u0026#34;UPDATE products SET price = price * 1.1 WHERE category = ?\u0026#34; ], \u0026#34;data_size\u0026#34;: \u0026#34;100K records per batch\u0026#34;, \u0026#34;concurrent_connections\u0026#34;: [1, 5, 10] } } DynamoDB Test Scenarios\ndynamodb_test_scenarios = { \u0026#34;single_table_operations\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Single table read/write operations\u0026#34;, \u0026#34;operations\u0026#34;: [ \u0026#34;PutItem\u0026#34;, \u0026#34;GetItem\u0026#34;, \u0026#34;UpdateItem\u0026#34;, \u0026#34;DeleteItem\u0026#34; ], \u0026#34;data_size\u0026#34;: \u0026#34;1M items\u0026#34;, \u0026#34;concurrent_requests\u0026#34;: [100, 500, 1000] }, \u0026#34;query_operations\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Query operations with different access patterns\u0026#34;, \u0026#34;operations\u0026#34;: [ \u0026#34;Query with partition key\u0026#34;, \u0026#34;Query with partition key and sort key\u0026#34;, \u0026#34;Scan with filter\u0026#34; ], \u0026#34;data_size\u0026#34;: \u0026#34;10M items\u0026#34;, \u0026#34;concurrent_requests\u0026#34;: [50, 100, 200] }, \u0026#34;batch_operations\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Batch read/write operations\u0026#34;, \u0026#34;operations\u0026#34;: [ \u0026#34;BatchGetItem\u0026#34;, \u0026#34;BatchWriteItem\u0026#34; ], \u0026#34;data_size\u0026#34;: \u0026#34;25 items per batch\u0026#34;, \u0026#34;concurrent_requests\u0026#34;: [10, 25, 50] } } ElastiCache Redis Test Scenarios\nredis_test_scenarios = { \u0026#34;basic_operations\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Basic Redis operations\u0026#34;, \u0026#34;operations\u0026#34;: [ \u0026#34;SET key value\u0026#34;, \u0026#34;GET key\u0026#34;, \u0026#34;DEL key\u0026#34;, \u0026#34;EXISTS key\u0026#34; ], \u0026#34;data_size\u0026#34;: \u0026#34;1M keys\u0026#34;, \u0026#34;concurrent_connections\u0026#34;: [50, 100, 200] }, \u0026#34;data_structures\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Redis data structure operations\u0026#34;, \u0026#34;operations\u0026#34;: [ \u0026#34;HSET hash field value\u0026#34;, \u0026#34;HGET hash field\u0026#34;, \u0026#34;LPUSH list value\u0026#34;, \u0026#34;LRANGE list start stop\u0026#34; ], \u0026#34;data_size\u0026#34;: \u0026#34;100K structures\u0026#34;, \u0026#34;concurrent_connections\u0026#34;: [25, 50, 100] }, \u0026#34;pipeline_operations\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Redis pipeline operations\u0026#34;, \u0026#34;operations\u0026#34;: [ \u0026#34;Pipeline with multiple SET operations\u0026#34;, \u0026#34;Pipeline with multiple GET operations\u0026#34; ], \u0026#34;data_size\u0026#34;: \u0026#34;1000 operations per pipeline\u0026#34;, \u0026#34;concurrent_connections\u0026#34;: [10, 25, 50] } } Bước 4: Thiết lập Baseline Performance Standards Performance Baselines # Baseline Performance Standards performance_baselines = { \u0026#34;rds_mysql\u0026#34;: { \u0026#34;throughput\u0026#34;: { \u0026#34;minimum_qps\u0026#34;: 1000, # Queries per second \u0026#34;target_qps\u0026#34;: 5000, \u0026#34;excellent_qps\u0026#34;: 10000 }, \u0026#34;latency\u0026#34;: { \u0026#34;max_avg_response_time\u0026#34;: 50, # milliseconds \u0026#34;max_p95_response_time\u0026#34;: 100, \u0026#34;max_p99_response_time\u0026#34;: 200 }, \u0026#34;resource_utilization\u0026#34;: { \u0026#34;max_cpu_utilization\u0026#34;: 80, # percentage \u0026#34;max_memory_utilization\u0026#34;: 85, \u0026#34;max_disk_utilization\u0026#34;: 90 } }, \u0026#34;dynamodb\u0026#34;: { \u0026#34;throughput\u0026#34;: { \u0026#34;minimum_ops_per_sec\u0026#34;: 1000, \u0026#34;target_ops_per_sec\u0026#34;: 5000, \u0026#34;excellent_ops_per_sec\u0026#34;: 10000 }, \u0026#34;latency\u0026#34;: { \u0026#34;max_avg_response_time\u0026#34;: 10, # milliseconds \u0026#34;max_p95_response_time\u0026#34;: 25, \u0026#34;max_p99_response_time\u0026#34;: 50 } }, \u0026#34;elasticache_redis\u0026#34;: { \u0026#34;throughput\u0026#34;: { \u0026#34;minimum_ops_per_sec\u0026#34;: 5000, \u0026#34;target_ops_per_sec\u0026#34;: 20000, \u0026#34;excellent_ops_per_sec\u0026#34;: 50000 }, \u0026#34;latency\u0026#34;: { \u0026#34;max_avg_response_time\u0026#34;: 1, # milliseconds \u0026#34;max_p95_response_time\u0026#34;: 5, \u0026#34;max_p99_response_time\u0026#34;: 10 } } } Bước 5: Định nghĩa Success Criteria và Thresholds Success Criteria\n# Success Criteria Definition success_criteria = { \u0026#34;performance\u0026#34;: { \u0026#34;throughput_achievement\u0026#34;: 0.9, # 90% of target throughput \u0026#34;latency_compliance\u0026#34;: 0.95, # 95% of requests within latency limits \u0026#34;error_rate_threshold\u0026#34;: 0.01 # 1% maximum error rate }, \u0026#34;stability\u0026#34;: { \u0026#34;uptime_requirement\u0026#34;: 0.999, # 99.9% uptime during test \u0026#34;consistency_check\u0026#34;: True, # Data consistency verification \u0026#34;resource_stability\u0026#34;: 0.95 # 95% resource utilization stability }, \u0026#34;scalability\u0026#34;: { \u0026#34;linear_scaling\u0026#34;: 0.8, # 80% linear scaling with load increase \u0026#34;resource_efficiency\u0026#34;: 0.7 # 70% resource utilization efficiency } } Regression Detection Thresholds\n# Regression Detection Configuration regression_thresholds = { \u0026#34;performance_degradation\u0026#34;: { \u0026#34;throughput_decrease\u0026#34;: 0.1, # 10% decrease in throughput \u0026#34;latency_increase\u0026#34;: 0.2, # 20% increase in latency \u0026#34;error_rate_increase\u0026#34;: 0.05 # 5% increase in error rate }, \u0026#34;cost_efficiency\u0026#34;: { \u0026#34;cost_per_operation_increase\u0026#34;: 0.15, # 15% increase in cost per operation \u0026#34;resource_utilization_decrease\u0026#34;: 0.2 # 20% decrease in resource utilization }, \u0026#34;stability_issues\u0026#34;: { \u0026#34;connection_drops\u0026#34;: 0.01, # 1% connection drop rate \u0026#34;timeout_increase\u0026#34;: 0.1 # 10% increase in timeouts } } Bước 6: Tạo Test Configuration Files Main Configuration File\n# benchmark_config.yaml benchmark: name: \u0026#34;AWS Database Benchmark Suite\u0026#34; version: \u0026#34;1.0.0\u0026#34; description: \u0026#34;Comprehensive database performance testing\u0026#34; environment: region: \u0026#34;ap-southeast-1\u0026#34; vpc_id: \u0026#34;vpc-xxxxxxxxx\u0026#34; subnet_ids: [\u0026#34;subnet-xxxxxxxxx\u0026#34;, \u0026#34;subnet-xxxxxxxxx\u0026#34;] databases: mysql: endpoint: \u0026#34;benchmark-mysql.xxxxxxxxx.ap-southeast-1.rds.amazonaws.com\u0026#34; port: 3306 username: \u0026#34;admin\u0026#34; password: \u0026#34;YourPassword123!\u0026#34; database: \u0026#34;benchmark_db\u0026#34; postgresql: endpoint: \u0026#34;benchmark-postgres.xxxxxxxxx.ap-southeast-1.rds.amazonaws.com\u0026#34; port: 5432 username: \u0026#34;admin\u0026#34; password: \u0026#34;YourPassword123!\u0026#34; database: \u0026#34;benchmark_db\u0026#34; dynamodb: table_name: \u0026#34;benchmark-table\u0026#34; region: \u0026#34;ap-southeast-1\u0026#34; redis: endpoint: \u0026#34;benchmark-redis.xxxxxxxxx.cache.amazonaws.com\u0026#34; port: 6379 workloads: - name: \u0026#34;OLTP_Standard\u0026#34; duration: 300 concurrent_users: [10, 50, 100, 200] warmup_time: 60 - name: \u0026#34;OLAP_Analytics\u0026#34; duration: 600 concurrent_users: [5, 10, 20] warmup_time: 120 - name: \u0026#34;NoSQL_High_Throughput\u0026#34; duration: 300 concurrent_users: [50, 100, 200, 500] warmup_time: 60 metrics: collection_interval: 5 # seconds storage: s3_bucket: \u0026#34;benchmark-results-xxxxxxxxx\u0026#34; cloudwatch_namespace: \u0026#34;DatabaseBenchmark\u0026#34; reporting: output_format: [\u0026#34;json\u0026#34;, \u0026#34;csv\u0026#34;, \u0026#34;html\u0026#34;] dashboard_url: \u0026#34;https://your-dashboard-url.com\u0026#34; email_notifications: true Test Data Generation Script\n# generate_test_data.py import random import string import json from datetime import datetime, timedelta class TestDataGenerator: def __init__(self, config): self.config = config self.data_sizes = { \u0026#34;small\u0026#34;: 1000, \u0026#34;medium\u0026#34;: 10000, \u0026#34;large\u0026#34;: 100000, \u0026#34;xlarge\u0026#34;: 1000000 } def generate_user_data(self, size): \u0026#34;\u0026#34;\u0026#34;Generate user test data\u0026#34;\u0026#34;\u0026#34; users = [] for i in range(size): user = { \u0026#34;id\u0026#34;: i + 1, \u0026#34;name\u0026#34;: f\u0026#34;User_{i}\u0026#34;, \u0026#34;email\u0026#34;: f\u0026#34;user{i}@example.com\u0026#34;, \u0026#34;created_at\u0026#34;: datetime.now() - timedelta(days=random.randint(1, 365)), \u0026#34;status\u0026#34;: random.choice([\u0026#34;active\u0026#34;, \u0026#34;inactive\u0026#34;, \u0026#34;pending\u0026#34;]) } users.append(user) return users def generate_product_data(self, size): \u0026#34;\u0026#34;\u0026#34;Generate product test data\u0026#34;\u0026#34;\u0026#34; categories = [\u0026#34;electronics\u0026#34;, \u0026#34;clothing\u0026#34;, \u0026#34;books\u0026#34;, \u0026#34;home\u0026#34;, \u0026#34;sports\u0026#34;] products = [] for i in range(size): product = { \u0026#34;id\u0026#34;: i + 1, \u0026#34;name\u0026#34;: f\u0026#34;Product_{i}\u0026#34;, \u0026#34;category\u0026#34;: random.choice(categories), \u0026#34;price\u0026#34;: round(random.uniform(10, 1000), 2), \u0026#34;stock\u0026#34;: random.randint(0, 1000), \u0026#34;created_at\u0026#34;: datetime.now() - timedelta(days=random.randint(1, 365)) } products.append(product) return products def generate_order_data(self, size, user_count, product_count): \u0026#34;\u0026#34;\u0026#34;Generate order test data\u0026#34;\u0026#34;\u0026#34; orders = [] for i in range(size): order = { \u0026#34;id\u0026#34;: i + 1, \u0026#34;user_id\u0026#34;: random.randint(1, user_count), \u0026#34;product_id\u0026#34;: random.randint(1, product_count), \u0026#34;quantity\u0026#34;: random.randint(1, 10), \u0026#34;total_amount\u0026#34;: round(random.uniform(10, 1000), 2), \u0026#34;order_date\u0026#34;: datetime.now() - timedelta(days=random.randint(1, 365)), \u0026#34;status\u0026#34;: random.choice([\u0026#34;pending\u0026#34;, \u0026#34;shipped\u0026#34;, \u0026#34;delivered\u0026#34;, \u0026#34;cancelled\u0026#34;]) } orders.append(order) return orders def save_test_data(self, data, filename): \u0026#34;\u0026#34;\u0026#34;Save test data to file\u0026#34;\u0026#34;\u0026#34; with open(filename, \u0026#39;w\u0026#39;) as f: json.dump(data, f, indent=2, default=str) if __name__ == \u0026#34;__main__\u0026#34;: generator = TestDataGenerator({}) # Generate test data users = generator.generate_user_data(10000) products = generator.generate_product_data(50000) orders = generator.generate_order_data(100000, 10000, 50000) # Save to files generator.save_test_data(users, \u0026#34;test_data_users.json\u0026#34;) generator.save_test_data(products, \u0026#34;test_data_products.json\u0026#34;) generator.save_test_data(orders, \u0026#34;test_data_orders.json\u0026#34;) Bước 7: Tạo Test Execution Plan Test Execution Schedule # test_execution_plan.py from datetime import datetime, timedelta import yaml class TestExecutionPlan: def __init__(self, config_file): with open(config_file, \u0026#39;r\u0026#39;) as f: self.config = yaml.safe_load(f) def create_execution_schedule(self): \u0026#34;\u0026#34;\u0026#34;Create detailed test execution schedule\u0026#34;\u0026#34;\u0026#34; schedule = { \u0026#34;preparation_phase\u0026#34;: { \u0026#34;duration\u0026#34;: \u0026#34;30 minutes\u0026#34;, \u0026#34;tasks\u0026#34;: [ \u0026#34;Environment validation\u0026#34;, \u0026#34;Test data generation\u0026#34;, \u0026#34;Database initialization\u0026#34;, \u0026#34;Baseline measurement\u0026#34; ] }, \u0026#34;execution_phase\u0026#34;: { \u0026#34;duration\u0026#34;: \u0026#34;4 hours\u0026#34;, \u0026#34;test_sequence\u0026#34;: [ { \u0026#34;database\u0026#34;: \u0026#34;mysql\u0026#34;, \u0026#34;workloads\u0026#34;: [\u0026#34;OLTP_Standard\u0026#34;, \u0026#34;OLAP_Analytics\u0026#34;], \u0026#34;duration\u0026#34;: \u0026#34;2 hours\u0026#34; }, { \u0026#34;database\u0026#34;: \u0026#34;postgresql\u0026#34;, \u0026#34;workloads\u0026#34;: [\u0026#34;OLTP_Standard\u0026#34;, \u0026#34;OLAP_Analytics\u0026#34;], \u0026#34;duration\u0026#34;: \u0026#34;2 hours\u0026#34; }, { \u0026#34;database\u0026#34;: \u0026#34;dynamodb\u0026#34;, \u0026#34;workloads\u0026#34;: [\u0026#34;NoSQL_High_Throughput\u0026#34;], \u0026#34;duration\u0026#34;: \u0026#34;1 hour\u0026#34; }, { \u0026#34;database\u0026#34;: \u0026#34;redis\u0026#34;, \u0026#34;workloads\u0026#34;: [\u0026#34;Cache_Operations\u0026#34;], \u0026#34;duration\u0026#34;: \u0026#34;1 hour\u0026#34; } ] }, \u0026#34;analysis_phase\u0026#34;: { \u0026#34;duration\u0026#34;: \u0026#34;1 hour\u0026#34;, \u0026#34;tasks\u0026#34;: [ \u0026#34;Results collection\u0026#34;, \u0026#34;Performance analysis\u0026#34;, \u0026#34;Regression detection\u0026#34;, \u0026#34;Report generation\u0026#34; ] } } return schedule # Usage planner = TestExecutionPlan(\u0026#34;benchmark_config.yaml\u0026#34;) schedule = planner.create_execution_schedule() print(yaml.dump(schedule, default_flow_style=False)) Tóm tắt Trong lab này, bạn đã:\n✅ Định nghĩa các workload patterns chuẩn (OLTP, OLAP, NoSQL) ✅ Thiết kế metrics collection framework ✅ Tạo test scenarios cho từng database service ✅ Thiết lập baseline performance standards ✅ Định nghĩa success criteria và regression thresholds ✅ Tạo configuration files và test data generator ✅ Lập kế hoạch execution chi tiết Bước tiếp theo: Xây dựng Automated Testing Framework\n"
},
{
	"uri": "//localhost:1313/vi/2-mfa-setup-for-aws-user-root/2.3-config-ec2-instance/",
	"title": "Cấu hình EC2 Instance và deploy backend",
	"tags": [],
	"description": "",
	"content": "Mở CMD: Nhập dòng lệnh sau:\nAWS Configure AWS Access Key ID: nhập Key ID AWs Secret Access Key ID: nhập Key ID bí mật Default region name: chọn region, ở đây là us-east-1 Default output format: nhập json Ssh đến EC2 bằng câu lệnh ssh -i \u0026#34;C:\\path\\to\\key.pem\u0026#34; ubuntu@[EC2-PUBLIC-IP] Thay C:\\path\\to\\ecourse-key.pem bằng đường dẫn thực tế đến file key. Thay [EC2-PUBLIC-IP] bằng IP public của EC2. Sau khi SSH thành công, chạy các lệnh sau:\n# Update system sudo apt update \u0026amp;\u0026amp; sudo apt upgrade -y # Install Node.js 18.x curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash - sudo apt-get install -y nodejs # Install PM2 (process manager) sudo npm install -g pm2 # Install Nginx (web server) sudo apt install nginx -y # Install Git sudo apt install git -y # Kiểm tra cài đặt node --version npm --version sau khi cài đặt các path cần thiết, chúng ta sẽ clone dự án back end trên git về để chuẩn bị triển khai lên EC2.\nchạy các lệnh sau:\n# Clone repository backend của bạn git clone [your-backend-repo-url] cd [your-backend-directory] # Install dependencies npm install # Tạo file environment cat \u0026gt; .env \u0026lt;\u0026lt; EOF MONGODB_URI=mongodb+srv://ecourse_user:[password]@ecourse-cluster.xxxxx.mongodb.net/ecourse PORT=3000 NODE_ENV=production JWT_SECRET=[your-jwt-secret] EOF Thay [your-backend-repo-url] bằng URL repository backend. Đường link \u0026ldquo;MONGODB_URI\u0026rdquo; đã được tạo trong mục 1.4, vui lòng xem lại. Thay [your-jwt-secret] bằng secret key cho JWT, nằm trong file .env của back end. Sau khi clone dự án xong, tiếp tục chạy các lệnh sau:\n# Build application npm run build # Start với PM2 pm2 start dist/main.js --name \u0026#34;ecourse-backend\u0026#34; # Save PM2 configuration pm2 save pm2 startup Sau đó, tạo file Nginx Configuration\nsudo nano /etc/nginx/sites-available/ecourse Nhập đoạn mã sau:\nserver { listen 80; server_name [EC2_Public_IP]; # Redirect all HTTP to HTTPS return 301 https://$host$request_uri; } server { listen 443 ssl; server_name [EC2_Public_IP]; ssl_certificate /etc/ssl/certs/selfsigned.crt; ssl_certificate_key /etc/ssl/private/selfsigned.key; location / { proxy_pass http://localhost:3000; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#39;upgrade\u0026#39;; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_cache_bypass $http_upgrade; } } Thay [EC2-PUBLIC-IP] bằng IP public của EC2. Tiếp tục chạy lệnh này để tạo Ssl cần khi triển khai front end lên Cloudfront vì EC2 chạy thông qua phương thức HTTP, còn Cloudfront chạy thông qua phương thức HTTPS:\nsudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 \\ -keyout /etc/ssl/private/selfsigned.key \\ -out /etc/ssl/certs/selfsigned.crt Lưu ý: lệnh trên chỉ tạo self-signed certificate nhằm cho quá trình phát triển. Giải pháp tốt nhất: Đăng ký domain và trỏ về IP EC2. Cài SSL miễn phí với Let\u0026rsquo;s Encrypt cho domain đó. Khi đó, frontend gọi API qua https://api.yourdomain.com/\u0026hellip; là chuẩn nhất, không bị cảnh báo bảo mật.\nSau khi tạo xong file Nginx, reload lại bằng lệnh:\nsudo nginx -t sudo systemctl reload nginx Sau khi chạy xong, test với Postman để kiểm tra xem backend api đã hoạt động chưa:\n"
},
{
	"uri": "//localhost:1313/vi/3-create-admin-user-and-group/",
	"title": "Tạo Admin Group và Admin User",
	"tags": [],
	"description": "",
	"content": "Tạo Admin Group Đăng nhập vào Bảng điều khiển ở trang AWS Web Service page\nNhấn vào tên tài khoản ở góc trên bên phải và chọn My Security Credentials\nLưu ý: Trong trường hợp không thấy menu My Security Credentials, bạn có thể click vào biểu tượng tìm kiếm và điền IAM. Sau đó click vào dịch vụ IAM để truy cập vào giao diện quản lý dịch vụ IAM.\nỞ thanh bên trái, chọn User Groups sau đó chọn Create Group\nDưới mục Name the group, nhập tên Group (Ví dụ: AdminGroup) và cuộn chuột xuống dưới\nỞ phần Attach permissions policies, gõ AdministratorAccesss vào thanh tìm kiếm và nhấn chọn nó. Cuối cùng, chọn Create Group.\nHoàn thành tạo admin group.\nTạo Admin User Ở thanh bên trái, chọn Users sau đó chọn Add User\nNhập tên User (Ví dụ: AdminUser).\nClick AWS Management Console access. Click Programmatic Access. Click Custom password rồi gõ một password tùy ý của bạn (lưu ý: bạn phải ghi nhớ mật khẩu này cho những lần đăng nhập trong tương lai). Bỏ chọn mục User must create a new password\u0026hellip;. Click Next:Permissions. Lưu ý: Bằng cách chọn AWS Management Console access, bạn vừa cho phép IAM User được truy cập vào AWS thông qua bảng điều khiển AWS trên web. Việc bỏ mục User must create a new password\u0026hellip; cho phép người dùng khi lần đầu đăng nhập vào IAM User đó không cần phải tạo mật khẩu mới.\nClick tab Add user to group và click AdminGroup mà chúng ta tạo trước đó.\nClick Next:Tags\nTags (thẻ) là một tùy chọn không bắt buộc để tổ chức, theo dõi, hoặc điều khiển truy cập của user, thế nên bạn có thể thêm tags hoặc không. Click Next:Review.\nKiểm tra thông tin và chọn Create user\nHoàn thành tạo user. Có thể download.csv để lưu trữ Access key.\nTạo admin user thành công.\nKiểm tra thông tin chi tiết user.\nLưu ý: Sau khi tạo user, bạn sẽ thấy hiện lên hộp thoại download thông tin access key và secret key. Đây là thông tin dùng để thực hiện Programmatic access tới các tài nguyên của AWS thông qua AWS CLI và AWS SDK. Tạm thời chúng ta sẽ chưa sử dụng tới.\nĐăng nhập vào AdminUser Trở về dịch vụ IAM, và chọn Users ở thanh bên trái.\nNhấn vào tên của IAM User mà bạn vừa chọn.\nTrong mục Summary, chọn tab Security credentials. Nhìn vào dòng Summary: Console sign-in link và copy đường link bên cạnh nó. Đây là đường link bạn dùng để đăng nhập vào IAM User.\nMở một tab ẩn danh của trình duyệt bạn đang sử dụng và paste đường link ấy vào thanh tìm kiếm.\nLưu ý: Việc đăng nhập bằng tab ẩn danh cho phép bạn đăng nhập vào AWS bằng IAM User mà không cần phải log out khỏi root user trong tab chính.\nNhập đúng tên IAM User và password mà bạn đã nhập ở phần tạo IAM User ở trên. Nhấn sign in.\nChúc mừng, bạn đã truy cập thành công vào tài khoản của bạn dưới danh nghĩa của một IAM User AdminUser.\nBước tiếp theo, chúng ta sẽ chuyển sang sử dụng IAM Role để nâng cao tính bảo mật hơn cho account của bạn nhé.\nTham khảo IAM User và Đăng Nhập Trong AWS Một IAM user là một định danh được tạo trong một tài khoản AWS, có quyền được tương tác với các tài nguyên AWS. Người dùng IAM đăng nhập bằng cách sử dụng ID tài khoản hoặc tên bí danh, tên người dùng của họ và mật khẩu. Tên người dùng IAM được cấu hình bởi quản trị viên của bạn. Tên người dùng IAM có thể là tên thân thiện như \u0026ldquo;Zhang\u0026rdquo;, hoặc là địa chỉ email như \u0026ldquo;zhang@example.com\u0026rdquo;. Tên người dùng IAM không thể chứa khoảng trắng, nhưng có thể chứa chữ cái in hoa và thường, số, và các ký tự + = , . @ _ -.\nMẹo Nếu người dùng IAM của bạn đã bật xác thực đa yếu tố (MFA), bạn phải có quyền truy cập vào thiết bị xác thực. Để biết thêm chi tiết, xem Sử dụng thiết bị MFA với trang đăng nhập IAM của bạn.\nĐể đăng nhập với tư cách người dùng IAM\nMở Bảng điều khiển Quản lý AWS tại https://console.aws.amazon.com/.\nTrang đăng nhập chính hiển thị. Chọn \u0026ldquo;IAM user\u0026rdquo;, nhập ID tài khoản (12 chữ số) hoặc bí danh và chọn \u0026ldquo;Next\u0026rdquo;.\nGhi chú Bạn có thể không cần phải nhập ID tài khoản hoặc bí danh nếu bạn đã đăng nhập trước đó với tài khoản IAM bằng trình duyệt hiện tại hoặc nếu bạn đang sử dụng URL đăng nhập tài khoản của bạn.\nNhập tên người dùng IAM và mật khẩu của bạn, sau đó chọn \u0026ldquo;Sign in\u0026rdquo;.\nNếu MFA được bật cho người dùng IAM của bạn, sau đó bạn sẽ được xác thực sử dụng nó.\nSau khi xác thực, Bảng điều khiển Quản lý AWS sẽ mở trang chủ Bảng điều khiển.\nTạo khóa truy cập (access key) cho tài khoản root user trên AWS Quyền tối thiểu cần thiết Để thực hiện các bước sau, bạn cần có ít nhất các quyền IAM (Identity and Access Management) sau đây:\nBạn phải đăng nhập với tư cách là tài khoản root user của AWS, điều này không yêu cầu bất kỳ quyền IAM bổ sung nào khác. Bạn không thể thực hiện các bước này với tư cách là người dùng IAM hoặc vai trò (role).\nSử dụng địa chỉ email và mật khẩu của tài khoản AWS để đăng nhập vào Bảng điều khiển quản lý AWS (AWS Management Console) với tư cách là tài khoản root user.\nỞ góc trên bên phải của bảng điều khiển, chọn tên hoặc số tài khoản của bạn, sau đó chọn Security Credentials (Thông tin xác thực bảo mật).\nỞ phần Access keys (Khóa truy cập), chọn Create access key (Tạo khóa truy cập). Nếu tùy chọn này không khả dụng, điều đó có nghĩa bạn đã có số lượng tối đa các khóa truy cập. Bạn phải xóa một trong các khóa truy cập hiện có trước khi tạo khóa mới. Để biết thêm thông tin, xem IAM Object Quotas trong Hướng dẫn Người dùng IAM.\nTrên trang Alternatives to root user access keys (Các phương án thay thế cho khóa truy cập tài khoản root user), xem xét các khuyến nghị về bảo mật. Để tiếp tục, chọn vào ô kiểm và sau đó chọn Create access key (Tạo khóa truy cập).\nTrên trang Retrieve access key (Trang Lấy lại khóa truy cập), Access key ID của bạn sẽ được hiển thị.\nDưới mục Secret access key (Khóa truy cập bí mật), chọn Show (Hiển thị) và sau đó sao chép Access key ID và Secret key từ cửa sổ trình duyệt của bạn, sau đó dán chúng vào một nơi an toàn. Tùy chọn khác, bạn có thể chọn Download .csv file (Tải xuống tệp .csv) để tải xuống một tệp có tên là rootkey.csv chứa Access key ID và Secret key. Lưu tệp ở một nơi an toàn.\nChọn Done (Hoàn thành). Khi bạn không còn cần khóa truy cập nữa, chúng tôi khuyến nghị bạn xóa nó hoặc ít nhất là xem xét vô hiệu hóa nó để không ai có thể lạm dụng.\nLưu ý: Các bước này chỉ áp dụng cho tài khoản root user trên AWS. Đối với các người dùng IAM hoặc vai trò (role), cách tạo và quản lý khóa truy cập có thể khác nhau.\nXóa một khóa truy cập cho người dùng gốc trên AWS Quyền tối thiểu Để thực hiện các bước sau, bạn phải có ít nhất các quyền IAM (Quản lý Quyền và Danh sách quyền) sau đây:\nBạn phải đăng nhập dưới tư cách người dùng gốc của tài khoản AWS, điều này không yêu cầu bất kỳ quyền AWS Identity and Access Management (IAM) bổ sung nào. Bạn không thể thực hiện các bước này dưới tư cách người dùng IAM hoặc vai trò. Sử dụng địa chỉ email và mật khẩu của tài khoản AWS để đăng nhập vào Bảng điều khiển Quản lý AWS dưới tư cách người dùng gốc của bạn. Ở góc trên bên phải của bảng điều khiển, chọn tên hoặc số tài khoản của bạn, sau đó chọn Security Credentials (Chứng chỉ Bảo mật). Trong phần Access keys (Khóa truy cập), chọn khóa truy cập mà bạn muốn xóa, sau đó, ở mục Actions (Thao tác), chọn Delete (Xóa). Lưu ý Theo cách khác, bạn có thể Deactivate (Ngưng hoạt động) một khóa truy cập thay vì xóa nó vĩnh viễn. Điều này giúp bạn có thể tiếp tục sử dụng nó trong tương lai mà không cần thay đổi cả ID khóa lẫn khóa bí mật. Trong khi khóa bị vô hiệu hóa, mọi yêu cầu sử dụng nó trong các yêu cầu tới AWS API sẽ thất bại với lỗi \u0026ldquo;access denied\u0026rdquo; (truy cập bị từ chối).\nTrên hộp thoại Delete (Xóa \u0026lt;ID khóa truy cập\u0026gt;), chọn Deactivate (Ngưng hoạt động), nhập ID khóa truy cập để xác nhận bạn muốn xóa nó, sau đó chọn Delete (Xóa).\n"
},
{
	"uri": "//localhost:1313/vi/1-create-new-aws-account/1.3-create-key-pair/",
	"title": "Tạo Key Pair",
	"tags": [],
	"description": "",
	"content": "Trong mục Network \u0026amp; Security của giao diện EC2:\nChọn Key Pairs Chọn Create key pair Trong giao diện khởi tạo:\nMục Name, đặt là ecourse-key Mục Key pair type, chọn RSA Mục Private key file format, chọn .pem Kéo xuống cuối trang chọn Create key pair Key pair là cần thiết khi khởi tạo EC2.\n"
},
{
	"uri": "//localhost:1313/vi/5-aws-database-benchmarking-suite/5.3-automated-framework/",
	"title": "Xây dựng Automated Testing Framework",
	"tags": [],
	"description": "",
	"content": "Xây dựng Automated Testing Framework Tổng quan Trong lab này, bạn sẽ xây dựng một automated testing framework hoàn chỉnh để thực hiện các benchmark tests một cách tự động.\nMục tiêu Xây dựng core benchmark engine Tạo database connectors cho các AWS services Implement metrics collection system Tạo test orchestration và scheduling Thời gian: 60 phút Bước 1: Tạo Core Benchmark Engine # benchmark_engine.py import time import threading import logging from datetime import datetime from typing import Dict, List, Any import boto3 import json class BenchmarkEngine: def __init__(self, config: Dict[str, Any]): self.config = config self.logger = self._setup_logging() self.results = [] self.test_runners = {} def _setup_logging(self): logging.basicConfig( level=logging.INFO, format=\u0026#39;%(asctime)s - %(name)s - %(levelname)s - %(message)s\u0026#39;, handlers=[ logging.FileHandler(\u0026#39;benchmark.log\u0026#39;), logging.StreamHandler() ] ) return logging.getLogger(__name__) def register_test_runner(self, database_type: str, runner): self.test_runners[database_type] = runner self.logger.info(f\u0026#34;Registered test runner for {database_type}\u0026#34;) def run_benchmark(self, test_config: Dict[str, Any]) -\u0026gt; Dict[str, Any]: test_id = f\u0026#34;{test_config[\u0026#39;database_type\u0026#39;]}_{test_config[\u0026#39;workload\u0026#39;]}_{datetime.now().strftime(\u0026#39;%Y%m%d_%H%M%S\u0026#39;)}\u0026#34; self.logger.info(f\u0026#34;Starting benchmark test: {test_id}\u0026#34;) # Initialize test environment self._prepare_test_environment(test_config) # Run warmup phase self._run_warmup(test_config) # Execute main test start_time = time.time() test_results = self._execute_test(test_config) end_time = time.time() # Compile results benchmark_result = { \u0026#34;test_id\u0026#34;: test_id, \u0026#34;database_type\u0026#34;: test_config[\u0026#34;database_type\u0026#34;], \u0026#34;workload\u0026#34;: test_config[\u0026#34;workload\u0026#34;], \u0026#34;start_time\u0026#34;: start_time, \u0026#34;end_time\u0026#34;: end_time, \u0026#34;duration\u0026#34;: end_time - start_time, \u0026#34;test_results\u0026#34;: test_results, \u0026#34;configuration\u0026#34;: test_config } self.results.append(benchmark_result) self.logger.info(f\u0026#34;Completed benchmark test: {test_id}\u0026#34;) return benchmark_result def _prepare_test_environment(self, test_config: Dict[str, Any]): database_type = test_config[\u0026#34;database_type\u0026#34;] if database_type in self.test_runners: self.test_runners[database_type].prepare_environment(test_config) def _run_warmup(self, test_config: Dict[str, Any]): warmup_duration = test_config.get(\u0026#34;warmup_time\u0026#34;, 60) self.logger.info(f\u0026#34;Running warmup for {warmup_duration} seconds...\u0026#34;) time.sleep(warmup_duration) def _execute_test(self, test_config: Dict[str, Any]) -\u0026gt; Dict[str, Any]: database_type = test_config[\u0026#34;database_type\u0026#34;] if database_type not in self.test_runners: raise ValueError(f\u0026#34;No test runner registered for {database_type}\u0026#34;) return self.test_runners[database_type].run_test(test_config) def save_results(self, filename: str = None): if filename is None: filename = f\u0026#34;benchmark_results_{datetime.now().strftime(\u0026#39;%Y%m%d_%H%M%S\u0026#39;)}.json\u0026#34; with open(filename, \u0026#39;w\u0026#39;) as f: json.dump(self.results, f, indent=2, default=str) self.logger.info(f\u0026#34;Results saved to {filename}\u0026#34;) Bước 2: Tạo MySQL Test Runner # mysql_test_runner.py import mysql.connector from mysql.connector import pooling from typing import Dict, Any, List import random import time import threading import queue class MySQLTestRunner: def __init__(self, config: Dict[str, Any]): self.config = config self.connection_pool = None def prepare_environment(self, test_config: Dict[str, Any]): pool_config = { \u0026#34;host\u0026#34;: test_config[\u0026#34;mysql\u0026#34;][\u0026#34;endpoint\u0026#34;], \u0026#34;port\u0026#34;: test_config[\u0026#34;mysql\u0026#34;][\u0026#34;port\u0026#34;], \u0026#34;user\u0026#34;: test_config[\u0026#34;mysql\u0026#34;][\u0026#34;username\u0026#34;], \u0026#34;password\u0026#34;: test_config[\u0026#34;mysql\u0026#34;][\u0026#34;password\u0026#34;], \u0026#34;database\u0026#34;: test_config[\u0026#34;mysql\u0026#34;][\u0026#34;database\u0026#34;], \u0026#34;pool_name\u0026#34;: \u0026#34;benchmark_pool\u0026#34;, \u0026#34;pool_size\u0026#34;: test_config.get(\u0026#34;max_connections\u0026#34;, 50), \u0026#34;autocommit\u0026#34;: True } self.connection_pool = mysql.connector.pooling.MySQLConnectionPool(**pool_config) self._create_test_tables() self._load_test_data(test_config) def _create_test_tables(self): connection = self.connection_pool.get_connection() cursor = connection.cursor() cursor.execute(\u0026#34;\u0026#34;\u0026#34; CREATE TABLE IF NOT EXISTS users ( id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(255) NOT NULL, email VARCHAR(255) UNIQUE NOT NULL, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, status ENUM(\u0026#39;active\u0026#39;, \u0026#39;inactive\u0026#39;, \u0026#39;pending\u0026#39;) DEFAULT \u0026#39;active\u0026#39;, INDEX idx_email (email), INDEX idx_status (status) ) \u0026#34;\u0026#34;\u0026#34;) cursor.execute(\u0026#34;\u0026#34;\u0026#34; CREATE TABLE IF NOT EXISTS products ( id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(255) NOT NULL, category VARCHAR(100) NOT NULL, price DECIMAL(10,2) NOT NULL, stock INT DEFAULT 0, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, INDEX idx_category (category), INDEX idx_price (price) ) \u0026#34;\u0026#34;\u0026#34;) connection.commit() cursor.close() connection.close() def _load_test_data(self, test_config: Dict[str, Any]): data_size = test_config.get(\u0026#34;data_size\u0026#34;, \u0026#34;medium\u0026#34;) sizes = {\u0026#34;small\u0026#34;: 1000, \u0026#34;medium\u0026#34;: 10000, \u0026#34;large\u0026#34;: 100000} num_users = sizes.get(data_size, 10000) connection = self.connection_pool.get_connection() cursor = connection.cursor() for i in range(num_users): cursor.execute(\u0026#34;\u0026#34;\u0026#34; INSERT INTO users (name, email, status) VALUES (%s, %s, %s) \u0026#34;\u0026#34;\u0026#34;, (f\u0026#34;User_{i}\u0026#34;, f\u0026#34;user{i}@example.com\u0026#34;, \u0026#34;active\u0026#34;)) connection.commit() cursor.close() connection.close() def run_test(self, test_config: Dict[str, Any]) -\u0026gt; Dict[str, Any]: workload = test_config[\u0026#34;workload\u0026#34;] concurrent_users = test_config[\u0026#34;concurrent_users\u0026#34;] duration = test_config[\u0026#34;duration\u0026#34;] operations = self._generate_operations(workload, concurrent_users) results = self._execute_concurrent_operations(operations, duration) return self._compile_results(results) def _generate_operations(self, workload: str, concurrent_users: int) -\u0026gt; List[Dict[str, Any]]: operations = [] if workload == \u0026#34;OLTP_Standard\u0026#34;: for i in range(concurrent_users): if random.random() \u0026lt; 0.7: # 70% reads operations.append({ \u0026#34;type\u0026#34;: \u0026#34;SELECT\u0026#34;, \u0026#34;query\u0026#34;: \u0026#34;SELECT * FROM users WHERE id = %s\u0026#34;, \u0026#34;params\u0026#34;: [random.randint(1, 10000)] }) else: # 30% writes operations.append({ \u0026#34;type\u0026#34;: \u0026#34;INSERT\u0026#34;, \u0026#34;query\u0026#34;: \u0026#34;INSERT INTO users (name, email) VALUES (%s, %s)\u0026#34;, \u0026#34;params\u0026#34;: [f\u0026#34;NewUser_{i}\u0026#34;, f\u0026#34;newuser{i}@example.com\u0026#34;] }) return operations def _execute_concurrent_operations(self, operations: List[Dict[str, Any]], duration: int) -\u0026gt; List[Dict[str, Any]]: results = [] start_time = time.time() def worker(operation_queue, results_queue): while time.time() - start_time \u0026lt; duration: try: operation = operation_queue.get_nowait() result = self._execute_operation(operation) results_queue.put(result) except queue.Empty: break operation_queue = queue.Queue() for operation in operations: operation_queue.put(operation) results_queue = queue.Queue() threads = [] for i in range(len(operations)): thread = threading.Thread(target=worker, args=(operation_queue, results_queue)) thread.start() threads.append(thread) for thread in threads: thread.join() while not results_queue.empty(): results.append(results_queue.get()) return results def _execute_operation(self, operation: Dict[str, Any]) -\u0026gt; Dict[str, Any]: start_time = time.time() try: connection = self.connection_pool.get_connection() cursor = connection.cursor() cursor.execute(operation[\u0026#34;query\u0026#34;], operation[\u0026#34;params\u0026#34;]) if operation[\u0026#34;type\u0026#34;] == \u0026#34;SELECT\u0026#34;: result = cursor.fetchall() else: connection.commit() result = cursor.rowcount cursor.close() connection.close() end_time = time.time() return { \u0026#34;success\u0026#34;: True, \u0026#34;operation\u0026#34;: operation[\u0026#34;type\u0026#34;], \u0026#34;start_time\u0026#34;: start_time, \u0026#34;end_time\u0026#34;: end_time, \u0026#34;duration\u0026#34;: end_time - start_time, \u0026#34;result\u0026#34;: result } except Exception as e: end_time = time.time() return { \u0026#34;success\u0026#34;: False, \u0026#34;operation\u0026#34;: operation[\u0026#34;type\u0026#34;], \u0026#34;start_time\u0026#34;: start_time, \u0026#34;end_time\u0026#34;: end_time, \u0026#34;duration\u0026#34;: end_time - start_time, \u0026#34;error\u0026#34;: str(e) } def _compile_results(self, results: List[Dict[str, Any]]) -\u0026gt; Dict[str, Any]: successful_ops = [r for r in results if r[\u0026#34;success\u0026#34;]] failed_ops = [r for r in results if not r[\u0026#34;success\u0026#34;]] if not successful_ops: return {\u0026#34;error\u0026#34;: \u0026#34;No successful operations\u0026#34;} durations = [r[\u0026#34;duration\u0026#34;] for r in successful_ops] return { \u0026#34;total_operations\u0026#34;: len(results), \u0026#34;successful_operations\u0026#34;: len(successful_ops), \u0026#34;failed_operations\u0026#34;: len(failed_ops), \u0026#34;success_rate\u0026#34;: len(successful_ops) / len(results), \u0026#34;average_duration\u0026#34;: sum(durations) / len(durations), \u0026#34;min_duration\u0026#34;: min(durations), \u0026#34;max_duration\u0026#34;: max(durations), \u0026#34;p50_duration\u0026#34;: sorted(durations)[len(durations) // 2], \u0026#34;p95_duration\u0026#34;: sorted(durations)[int(len(durations) * 0.95)], \u0026#34;p99_duration\u0026#34;: sorted(durations)[int(len(durations) * 0.99)], \u0026#34;operations_per_second\u0026#34;: len(successful_ops) / sum(durations) } Bước 3: Tạo DynamoDB Test Runner # dynamodb_test_runner.py import boto3 from botocore.exceptions import ClientError from typing import Dict, Any, List import random import time import threading import queue class DynamoDBTestRunner: def __init__(self, config: Dict[str, Any]): self.config = config self.dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;, region_name=config[\u0026#39;dynamodb\u0026#39;][\u0026#39;region\u0026#39;]) self.table = None def prepare_environment(self, test_config: Dict[str, Any]): table_name = test_config[\u0026#34;dynamodb\u0026#34;][\u0026#34;table_name\u0026#34;] self.table = self.dynamodb.Table(table_name) self._load_test_data(test_config) def _load_test_data(self, test_config: Dict[str, Any]): data_size = test_config.get(\u0026#34;data_size\u0026#34;, \u0026#34;medium\u0026#34;) sizes = {\u0026#34;small\u0026#34;: 1000, \u0026#34;medium\u0026#34;: 10000, \u0026#34;large\u0026#34;: 100000} num_items = sizes.get(data_size, 10000) with self.table.batch_writer() as batch: for i in range(num_items): item = { \u0026#39;id\u0026#39;: f\u0026#34;item_{i}\u0026#34;, \u0026#39;name\u0026#39;: f\u0026#34;Item {i}\u0026#34;, \u0026#39;category\u0026#39;: random.choice([\u0026#39;electronics\u0026#39;, \u0026#39;clothing\u0026#39;, \u0026#39;books\u0026#39;]), \u0026#39;price\u0026#39;: random.randint(10, 1000), \u0026#39;stock\u0026#39;: random.randint(0, 100), \u0026#39;created_at\u0026#39;: int(time.time()) } batch.put_item(Item=item) def run_test(self, test_config: Dict[str, Any]) -\u0026gt; Dict[str, Any]: workload = test_config[\u0026#34;workload\u0026#34;] concurrent_users = test_config[\u0026#34;concurrent_users\u0026#34;] duration = test_config[\u0026#34;duration\u0026#34;] operations = self._generate_operations(workload, concurrent_users) results = self._execute_concurrent_operations(operations, duration) return self._compile_results(results) def _generate_operations(self, workload: str, concurrent_users: int) -\u0026gt; List[Dict[str, Any]]: operations = [] if workload == \u0026#34;NoSQL_High_Throughput\u0026#34;: for i in range(concurrent_users): if random.random() \u0026lt; 0.8: # 80% reads operations.append({ \u0026#34;type\u0026#34;: \u0026#34;GetItem\u0026#34;, \u0026#34;key\u0026#34;: {\u0026#34;id\u0026#34;: f\u0026#34;item_{random.randint(1, 10000)}\u0026#34;} }) else: # 20% writes operations.append({ \u0026#34;type\u0026#34;: \u0026#34;PutItem\u0026#34;, \u0026#34;item\u0026#34;: { \u0026#34;id\u0026#34;: f\u0026#34;new_item_{i}_{int(time.time())}\u0026#34;, \u0026#34;name\u0026#34;: f\u0026#34;New Item {i}\u0026#34;, \u0026#34;category\u0026#34;: random.choice([\u0026#39;electronics\u0026#39;, \u0026#39;clothing\u0026#39;, \u0026#39;books\u0026#39;]), \u0026#34;price\u0026#34;: random.randint(10, 1000), \u0026#34;stock\u0026#34;: random.randint(0, 100), \u0026#34;created_at\u0026#34;: int(time.time()) } }) return operations def _execute_concurrent_operations(self, operations: List[Dict[str, Any]], duration: int) -\u0026gt; List[Dict[str, Any]]: results = [] start_time = time.time() def worker(operation_queue, results_queue): while time.time() - start_time \u0026lt; duration: try: operation = operation_queue.get_nowait() result = self._execute_operation(operation) results_queue.put(result) except queue.Empty: break operation_queue = queue.Queue() for operation in operations: operation_queue.put(operation) results_queue = queue.Queue() threads = [] for i in range(len(operations)): thread = threading.Thread(target=worker, args=(operation_queue, results_queue)) thread.start() threads.append(thread) for thread in threads: thread.join() while not results_queue.empty(): results.append(results_queue.get()) return results def _execute_operation(self, operation: Dict[str, Any]) -\u0026gt; Dict[str, Any]: start_time = time.time() try: if operation[\u0026#34;type\u0026#34;] == \u0026#34;GetItem\u0026#34;: response = self.table.get_item(Key=operation[\u0026#34;key\u0026#34;]) result = response.get(\u0026#34;Item\u0026#34;) elif operation[\u0026#34;type\u0026#34;] == \u0026#34;PutItem\u0026#34;: response = self.table.put_item(Item=operation[\u0026#34;item\u0026#34;]) result = response end_time = time.time() return { \u0026#34;success\u0026#34;: True, \u0026#34;operation\u0026#34;: operation[\u0026#34;type\u0026#34;], \u0026#34;start_time\u0026#34;: start_time, \u0026#34;end_time\u0026#34;: end_time, \u0026#34;duration\u0026#34;: end_time - start_time, \u0026#34;result\u0026#34;: result } except ClientError as e: end_time = time.time() return { \u0026#34;success\u0026#34;: False, \u0026#34;operation\u0026#34;: operation[\u0026#34;type\u0026#34;], \u0026#34;start_time\u0026#34;: start_time, \u0026#34;end_time\u0026#34;: end_time, \u0026#34;duration\u0026#34;: end_time - start_time, \u0026#34;error\u0026#34;: str(e) } def _compile_results(self, results: List[Dict[str, Any]]) -\u0026gt; Dict[str, Any]: successful_ops = [r for r in results if r[\u0026#34;success\u0026#34;]] failed_ops = [r for r in results if not r[\u0026#34;success\u0026#34;]] if not successful_ops: return {\u0026#34;error\u0026#34;: \u0026#34;No successful operations\u0026#34;} durations = [r[\u0026#34;duration\u0026#34;] for r in successful_ops] return { \u0026#34;total_operations\u0026#34;: len(results), \u0026#34;successful_operations\u0026#34;: len(successful_ops), \u0026#34;failed_operations\u0026#34;: len(failed_ops), \u0026#34;success_rate\u0026#34;: len(successful_ops) / len(results), \u0026#34;average_duration\u0026#34;: sum(durations) / len(durations), \u0026#34;min_duration\u0026#34;: min(durations), \u0026#34;max_duration\u0026#34;: max(durations), \u0026#34;p50_duration\u0026#34;: sorted(durations)[len(durations) // 2], \u0026#34;p95_duration\u0026#34;: sorted(durations)[int(len(durations) * 0.95)], \u0026#34;p99_duration\u0026#34;: sorted(durations)[int(len(durations) * 0.99)], \u0026#34;operations_per_second\u0026#34;: len(successful_ops) / sum(durations) } Bước 4: Tạo Main Execution Script # main.py import yaml import argparse import sys from benchmark_engine import BenchmarkEngine from mysql_test_runner import MySQLTestRunner from dynamodb_test_runner import DynamoDBTestRunner def load_config(config_file: str) -\u0026gt; dict: with open(config_file, \u0026#39;r\u0026#39;) as f: return yaml.safe_load(f) def setup_benchmark_engine(config: dict) -\u0026gt; BenchmarkEngine: engine = BenchmarkEngine(config) # Register test runners if \u0026#39;mysql\u0026#39; in config[\u0026#39;databases\u0026#39;]: mysql_runner = MySQLTestRunner(config) engine.register_test_runner(\u0026#39;mysql\u0026#39;, mysql_runner) if \u0026#39;dynamodb\u0026#39; in config[\u0026#39;databases\u0026#39;]: dynamodb_runner = DynamoDBTestRunner(config) engine.register_test_runner(\u0026#39;dynamodb\u0026#39;, dynamodb_runner) return engine def run_single_test(engine: BenchmarkEngine, test_config: dict): print(f\u0026#34;Running benchmark test: {test_config[\u0026#39;database_type\u0026#39;]} - {test_config[\u0026#39;workload\u0026#39;]}\u0026#34;) result = engine.run_benchmark(test_config) print(f\u0026#34;Test completed:\u0026#34;) print(f\u0026#34; - Operations per second: {result[\u0026#39;test_results\u0026#39;].get(\u0026#39;operations_per_second\u0026#39;, \u0026#39;N/A\u0026#39;)}\u0026#34;) print(f\u0026#34; - Average latency: {result[\u0026#39;test_results\u0026#39;].get(\u0026#39;average_duration\u0026#39;, \u0026#39;N/A\u0026#39;)}ms\u0026#34;) print(f\u0026#34; - Success rate: {result[\u0026#39;test_results\u0026#39;].get(\u0026#39;success_rate\u0026#39;, \u0026#39;N/A\u0026#39;)}\u0026#34;) return result def main(): parser = argparse.ArgumentParser(description=\u0026#39;AWS Database Benchmark Suite\u0026#39;) parser.add_argument(\u0026#39;--config\u0026#39;, required=True, help=\u0026#39;Configuration file path\u0026#39;) parser.add_argument(\u0026#39;--database\u0026#39;, required=True, help=\u0026#39;Database type\u0026#39;) parser.add_argument(\u0026#39;--workload\u0026#39;, required=True, help=\u0026#39;Workload type\u0026#39;) args = parser.parse_args() # Load configuration try: config = load_config(args.config) except Exception as e: print(f\u0026#34;Error loading configuration: {e}\u0026#34;) sys.exit(1) # Setup engine engine = setup_benchmark_engine(config) # Create test config test_config = { \u0026#39;database_type\u0026#39;: args.database, \u0026#39;workload\u0026#39;: args.workload, \u0026#39;concurrent_users\u0026#39;: 50, \u0026#39;duration\u0026#39;: 300, \u0026#39;warmup_time\u0026#39;: 60 } # Run test result = run_single_test(engine, test_config) # Save results engine.save_results() if __name__ == \u0026#39;__main__\u0026#39;: main() Bước 5: Tạo Configuration File # benchmark_config.yaml benchmark: name: \u0026#34;AWS Database Benchmark Suite\u0026#34; version: \u0026#34;1.0.0\u0026#34; description: \u0026#34;Comprehensive database performance testing\u0026#34; environment: region: \u0026#34;ap-southeast-1\u0026#34; vpc_id: \u0026#34;vpc-xxxxxxxxx\u0026#34; subnet_ids: [\u0026#34;subnet-xxxxxxxxx\u0026#34;, \u0026#34;subnet-xxxxxxxxx\u0026#34;] databases: mysql: endpoint: \u0026#34;benchmark-mysql.xxxxxxxxx.ap-southeast-1.rds.amazonaws.com\u0026#34; port: 3306 username: \u0026#34;admin\u0026#34; password: \u0026#34;YourPassword123!\u0026#34; database: \u0026#34;benchmark_db\u0026#34; dynamodb: table_name: \u0026#34;benchmark-table\u0026#34; region: \u0026#34;ap-southeast-1\u0026#34; workloads: - name: \u0026#34;OLTP_Standard\u0026#34; duration: 300 concurrent_users: [10, 50, 100, 200] warmup_time: 60 - name: \u0026#34;NoSQL_High_Throughput\u0026#34; duration: 300 concurrent_users: [50, 100, 200, 500] warmup_time: 60 metrics: collection_interval: 5 # seconds storage: s3_bucket: \u0026#34;benchmark-results-xxxxxxxxx\u0026#34; cloudwatch_namespace: \u0026#34;DatabaseBenchmark\u0026#34; reporting: output_format: [\u0026#34;json\u0026#34;, \u0026#34;csv\u0026#34;, \u0026#34;html\u0026#34;] dashboard_url: \u0026#34;https://your-dashboard-url.com\u0026#34; Bước 6: Chạy Benchmark Test # Install dependencies pip install mysql-connector-python boto3 pyyaml # Run MySQL benchmark python main.py --config benchmark_config.yaml --database mysql --workload OLTP_Standard # Run DynamoDB benchmark python main.py --config benchmark_config.yaml --database dynamodb --workload NoSQL_High_Throughput Tóm tắt Trong lab này, bạn đã:\n✅ Xây dựng core benchmark engine với threading và concurrency ✅ Tạo database connectors cho MySQL và DynamoDB ✅ Implement automated test execution ✅ Tạo configuration system ✅ Xây dựng main execution script Bước tiếp theo: Tạo Comparison Tools và Regression Detection\n"
},
{
	"uri": "//localhost:1313/vi/1-create-new-aws-account/1.4-create-mongodb-database/",
	"title": "Cấu hình database với MongoDB",
	"tags": [],
	"description": "",
	"content": "Cấu hình Cluster Cấu hình tài khoản Truy cập trang chủ MongoDB: MongoDB Tạo tài khoản Mongo DB Sau khi tạo xong tài khoản, tại giao diện chính chọn Cluster Chọn Build a Cluster Cấu hình Cluster Chọn loại Cluster: chọn Free Chọn Name: đặt tên phù hợp, hoặc để mặc định là Cluster0 Chọn Provider: Tích vào ô AWS Chọn Region: Chọn Region cùng với Region của EC2 và các dịch vụ khác trên AWS để tránh sự cố Kiểm tra lại thông tin, và chọn Create Deployment Tạo kết nối Cluster Sau khi hoàn tất cấu hình Cluster, chúng ta đến với bước tạo kết nối CLuster. Ở trang Set up connection, sau khi phân quyền, các cấu hình có thể để mặc định Đến trang Choose a connection method, ở mục Connect to your application, chọn Drivers Ở mục 3. , copy đường link đến Cluster, có dạng \u0026ldquo;mongodb+srv://\u0026lt;db_username\u0026gt;:\u0026lt;db_password\u0026gt;@cluster0\u0026hellip;\u0026rdquo;, thay thế \u0026lt;db_username\u0026gt; và \u0026lt;db_password\u0026gt; bằng username và password ở trang Set up connection ở trên. Chúng ta cần đường link này để kết nối được database và EC2. "
},
{
	"uri": "//localhost:1313/vi/4-verify-new-account/",
	"title": "Hỗ trợ Xác thực Tài khoản",
	"tags": [],
	"description": "",
	"content": "Nội dung:\nKiểm tra các thông tin Tạo case hỗ trợ với AWS Support Trong quá trình khởi tạo tài khoản AWS, ở bước xác thực thông tin số điện thoại liên lạc, đôi khi sẽ xảy ra tình trạng không nhận được tin nhắn SMS hoặc cuộc gọi từ phía AWS. Trong trường hợp đó, hãy làm theo các bước sau để hoàn thành việc xác nhận thông tin tài khoản:\nKiểm tra các thông tin Đầu tiên, hãy kiểm tra lại các thông tin tài khoản của bạn và đảm bảo chúng đã được nhập chính xác:\nBạn đã nhập thông tin số điện thoại và chọn mã vùng quốc tế chính xác để nhận cuộc gọi. Nếu bạn sử dụng điện thoại di động, kiểm tra điện thoại của bạn để chắc chắn bạn vẫn đang trong vòng phủ sóng để nhận cuộc gọi. Thông tin về phương thức thanh toán đã được nhập chính xác. Hãy chắc chắn rằng số điện thoại mà bạn cung cấp trong tài khoản AWS của bạn có thể liên lạc được.\nTạo case hỗ trợ với AWS Support Sau khi kiểm tra thông tin chính xác nhưng vẫn chưa nhận được cuộc gọi xác thực, AWS Support sẽ hỗ trợ bạn kích hoạt tài khoản một cách thủ công.\nTruy cập vào AWS Support console, chọn Create case. Chọn Account and billing support và nhập các thông tin hỗ trợ: Type: chọn Account. Category: chọn Activation. Subject: viết ngắn gọn tình trạng gặp phải của bạn (VD: Did not receive an SMS message or call for verification) Description: Cung cấp chi tiết tình trạng gặp phải và thông tin về thời gian bạn cần hỗ trợ kích hoạt tài khoản. Attachments: Đính kèm hình ảnh mô tả bước xác thực đang vướng phải. Ở mục Contact options, chọn Chat ở Contact methods. Chọn Submit. 5. Đội ngũ AWS Support sẽ liên lạc và hỗ trợ kích hoạt tài khoản của bạn.\nBạn có thể tạo yêu cầu hỗ trợ với AWS Support ngay cả khi tài khoản của bạn chưa được kích hoạt.\n"
},
{
	"uri": "//localhost:1313/vi/5-aws-database-benchmarking-suite/",
	"title": "AWS Database Benchmarking Suite",
	"tags": [],
	"description": "",
	"content": "AWS Database Benchmarking Suite - Bộ công cụ đánh giá hiệu năng cơ sở dữ liệu AWS Tổng quan Trong workshop này, bạn sẽ xây dựng một bộ công cụ comprehensive để test performance của các AWS database services khác nhau dưới các workload khác nhau. Bạn sẽ học cách thiết kế và triển khai một hệ thống benchmarking tự động, so sánh kết quả, phát hiện performance regression, và tạo báo cáo dashboard.\nMục tiêu học tập Hiểu về các AWS database services chính (RDS, DynamoDB, Aurora, ElastiCache) Thiết kế methodology testing chuẩn hóa cho database performance Xây dựng automated benchmark execution system Tạo tools so sánh kết quả và phát hiện regression Thiết kế reporting dashboard Viết best practices documentation Kiến thức cần thiết Hiểu cơ bản về AWS services (EC2, IAM, CloudWatch) Kiến thức về database concepts Kinh nghiệm với Python hoặc Node.js Hiểu về performance testing concepts Thời gian ước tính Lab 5.1: 30 phút - Setup môi trường và infrastructure Lab 5.2: 45 phút - Thiết kế benchmark methodology Lab 5.3: 60 phút - Xây dựng automated testing framework Lab 5.4: 45 phút - Tạo comparison tools và regression detection Lab 5.5: 30 phút - Xây dựng reporting dashboard Lab 5.6: 30 phút - Viết best practices documentation Chi phí ước tính RDS instances: ~$50-100 (tùy theo instance type và thời gian sử dụng) DynamoDB: ~$10-20 (cho testing workload) EC2 instances: ~$20-40 (cho benchmark runner) CloudWatch: ~$5-10 Tổng cộng: ~$85-170 cho toàn bộ workshop Lưu ý quan trọng: Workshop này sẽ tạo ra các AWS resources có tính phí. Hãy đảm bảo xóa tất cả resources sau khi hoàn thành để tránh phát sinh chi phí không cần thiết.\nNội dung chính Thiết lập Infrastructure và Môi trường Thiết kế Benchmark Methodology Xây dựng Automated Testing Framework Tạo Comparison Tools và Regression Detection Xây dựng Reporting Dashboard Viết Best Practices Documentation Kiến trúc tổng thể graph TD\rA[Benchmark Runner] --\u0026gt; B[RDS MySQL]\rA --\u0026gt; C[RDS PostgreSQL]\rA --\u0026gt; D[DynamoDB]\rA --\u0026gt; E[ElastiCache Redis]\rA --\u0026gt; F[Aurora]\rG[CloudWatch] --\u0026gt; A\rH[Results Storage] --\u0026gt; A\rI[Dashboard] --\u0026gt; H\rJ[Comparison Engine] --\u0026gt; H Các AWS Services sẽ sử dụng EC2: Benchmark runner instances RDS: MySQL, PostgreSQL, Aurora databases DynamoDB: NoSQL database testing ElastiCache: Redis caching layer CloudWatch: Monitoring và metrics S3: Lưu trữ benchmark results Lambda: Automated cleanup và processing IAM: Security và permissions "
},
{
	"uri": "//localhost:1313/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]